{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpaCy for NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gy-etJOCJvKc"
      },
      "source": [
        "# Using spaCy for Natural Language Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AO_bV4irpqhg"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F_2Vv5L2J2Q0"
      },
      "source": [
        "Load your language model. \"en\" loads the small english model \"en_core_web_sm\" which is already installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWY0PlRUpvLv"
      },
      "source": [
        "nlp = spacy.load('en')"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IFbFsN3YqXvh"
      },
      "source": [
        "vocab is a storage class for vocabulary and other data shared across a language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56zfkJDqqzGp",
        "outputId": "72ae4225-0107-4f31-e454-f1b866ab6b12"
      },
      "source": [
        "nlp.vocab.length"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "478"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_UddYMKq2Fy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3dbf9245-9ba1-4db2-905e-c96cb9d2450c"
      },
      "source": [
        "nlp.vocab[0].text\n",
        "# This statement will print out text, if there is an equivalent string for the hash value at that index of the vocab\n",
        "# If you remove .text, it prints the hash value at the location\n",
        "# 454 is the last index which can print a string"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KrxC7WC0Ob9u"
      },
      "source": [
        "**Bonus:** *Can you find out whether the first index of vocab contains a number? An alphabet? Use nlp.vocab[].is_num and .is_alpha* "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSfOLmsqOflc"
      },
      "source": [
        ""
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzl4-kdsKsl0"
      },
      "source": [
        "## Exploring the pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks6BNGkAtYjW",
        "outputId": "c489b288-859c-4fd5-8461-d10e0bc67e76"
      },
      "source": [
        "nlp.pipe_names"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tagger', 'parser', 'ner']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fpMETj7NTNTb"
      },
      "source": [
        "I've used the first line from Wizard of Oz. The article will explain some topics using the results from this, and other texts. Feel free to play around with them later!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7RJi1uc5K5v"
      },
      "source": [
        "text = \"Dorothy lived in the midst of the great Kansas prairies, with Uncle Harry, who was a farmer, and Aunt Em, who was the farmer's wife.\"\n",
        "doc_oz = nlp(text)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6qf4Ose8LM-y"
      },
      "source": [
        "Tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lVyclaCo7dE9",
        "outputId": "1a33bb0d-c20e-43f8-8c3a-2ed1ea368b74"
      },
      "source": [
        "[token.text for token in doc_oz]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Dorothy',\n",
              " 'lived',\n",
              " 'in',\n",
              " 'the',\n",
              " 'midst',\n",
              " 'of',\n",
              " 'the',\n",
              " 'great',\n",
              " 'Kansas',\n",
              " 'prairies',\n",
              " ',',\n",
              " 'with',\n",
              " 'Uncle',\n",
              " 'Harry',\n",
              " ',',\n",
              " 'who',\n",
              " 'was',\n",
              " 'a',\n",
              " 'farmer',\n",
              " ',',\n",
              " 'and',\n",
              " 'Aunt',\n",
              " 'Em',\n",
              " ',',\n",
              " 'who',\n",
              " 'was',\n",
              " 'the',\n",
              " 'farmer',\n",
              " \"'s\",\n",
              " 'wife',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tXiPTtFZHLG"
      },
      "source": [
        "### Part of Speech"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUn_czzm6o-j",
        "outputId": "139437e1-febb-4feb-94fc-5298aa8c70a1"
      },
      "source": [
        "[(token.text, token.pos_, spacy.explain(token.pos_)) for token in doc_oz]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Dorothy', 'PROPN', 'proper noun'),\n",
              " ('lived', 'VERB', 'verb'),\n",
              " ('in', 'ADP', 'adposition'),\n",
              " ('the', 'DET', 'determiner'),\n",
              " ('midst', 'NOUN', 'noun'),\n",
              " ('of', 'ADP', 'adposition'),\n",
              " ('the', 'DET', 'determiner'),\n",
              " ('great', 'ADJ', 'adjective'),\n",
              " ('Kansas', 'PROPN', 'proper noun'),\n",
              " ('prairies', 'NOUN', 'noun'),\n",
              " (',', 'PUNCT', 'punctuation'),\n",
              " ('with', 'ADP', 'adposition'),\n",
              " ('Uncle', 'PROPN', 'proper noun'),\n",
              " ('Harry', 'PROPN', 'proper noun'),\n",
              " (',', 'PUNCT', 'punctuation'),\n",
              " ('who', 'PRON', 'pronoun'),\n",
              " ('was', 'AUX', 'auxiliary'),\n",
              " ('a', 'DET', 'determiner'),\n",
              " ('farmer', 'NOUN', 'noun'),\n",
              " (',', 'PUNCT', 'punctuation'),\n",
              " ('and', 'CCONJ', 'coordinating conjunction'),\n",
              " ('Aunt', 'PROPN', 'proper noun'),\n",
              " ('Em', 'PROPN', 'proper noun'),\n",
              " (',', 'PUNCT', 'punctuation'),\n",
              " ('who', 'PRON', 'pronoun'),\n",
              " ('was', 'AUX', 'auxiliary'),\n",
              " ('the', 'DET', 'determiner'),\n",
              " ('farmer', 'NOUN', 'noun'),\n",
              " (\"'s\", 'PART', 'particle'),\n",
              " ('wife', 'NOUN', 'noun'),\n",
              " ('.', 'PUNCT', 'punctuation')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zfXfN1YA7H4I",
        "outputId": "962a6446-c96e-469c-f293-5c6da5d859b6"
      },
      "source": [
        "#frequency of POS tags\n",
        "pos_freq = doc_oz.count_by(spacy.attrs.POS)\n",
        "for k,v in sorted(pos_freq.items()):\n",
        "    print(f'{doc_oz.vocab[k].text:{6}}: {v}')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ADJ   : 1\n",
            "ADP   : 3\n",
            "AUX   : 2\n",
            "CCONJ : 1\n",
            "DET   : 4\n",
            "NOUN  : 5\n",
            "PART  : 1\n",
            "PRON  : 2\n",
            "PROPN : 6\n",
            "PUNCT : 5\n",
            "VERB  : 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPFvR7nrRnfy"
      },
      "source": [
        "**Bonus:** *Try finding the POS of two sentences that use homonyms. Eg- \"Bear with me.\" and \"I saw a bear today.\" What POS does the word bear have in each sentence?*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLGHVwqISX9m",
        "outputId": "cf820f22-7f05-4330-9764-b4654e14616d"
      },
      "source": [
        "doc1 = nlp(\"\")\n",
        "doc2 = nlp(\"\")\n",
        "\n",
        "for token in doc1:\n",
        "  print(token.text, token.pos_, spacy.explain(token.pos_))\n",
        "print(\"-------------\")\n",
        "for token in doc2:\n",
        "  print(token.text, token.pos_, spacy.explain(token.pos_))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhfscM17Lank"
      },
      "source": [
        "### Parser - Dependancy parsing, sentence boundary detection and chunking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NNnUtRlMtKD"
      },
      "source": [
        "Sentence boundary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2tXHbx0MTqS",
        "outputId": "24fd5011-1bbe-48c0-8196-cacd7dbbd0b4"
      },
      "source": [
        "doc_two = nlp(\"The Bible is a religious book. A Tale of Two Cities was written by Charles Dickens and first published in 1859. It is set in London and Paris before and during the French Revolution.\")\n",
        "for sent in doc_two.sents:\n",
        "  print(sent)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Bible is a religious book.\n",
            "A Tale of Two Cities was written by Charles Dickens and first published in 1859.\n",
            "It is set in London and Paris before and during the French Revolution.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7kV_c1N7W8T",
        "outputId": "79825902-b428-405a-968e-281705bcae12"
      },
      "source": [
        "[(token.text, token.dep_) for token in doc_oz]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Dorothy', 'nsubj'),\n",
              " ('lived', 'ROOT'),\n",
              " ('in', 'prep'),\n",
              " ('the', 'det'),\n",
              " ('midst', 'pobj'),\n",
              " ('of', 'prep'),\n",
              " ('the', 'det'),\n",
              " ('great', 'amod'),\n",
              " ('Kansas', 'compound'),\n",
              " ('prairies', 'pobj'),\n",
              " (',', 'punct'),\n",
              " ('with', 'prep'),\n",
              " ('Uncle', 'compound'),\n",
              " ('Harry', 'pobj'),\n",
              " (',', 'punct'),\n",
              " ('who', 'nsubj'),\n",
              " ('was', 'relcl'),\n",
              " ('a', 'det'),\n",
              " ('farmer', 'attr'),\n",
              " (',', 'punct'),\n",
              " ('and', 'cc'),\n",
              " ('Aunt', 'compound'),\n",
              " ('Em', 'conj'),\n",
              " (',', 'punct'),\n",
              " ('who', 'nsubj'),\n",
              " ('was', 'relcl'),\n",
              " ('the', 'det'),\n",
              " ('farmer', 'poss'),\n",
              " (\"'s\", 'case'),\n",
              " ('wife', 'attr'),\n",
              " ('.', 'punct')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGNzqaPfMLba"
      },
      "source": [
        "Importing the visualiser to better understand dependancies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhZvSCGC8BWI"
      },
      "source": [
        "from spacy import displacy"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 703
        },
        "id": "GGjx3agO7wD-",
        "outputId": "8abf312b-f86c-4d6c-e862-e82c565e7d20"
      },
      "source": [
        "options = {\"compact\": True, \"color\": \"blue\"}\n",
        "displacy.render(doc_oz, style=\"dep\",jupyter=True, options=options )"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"1a3582c6dc754b9b8b0b74daf5b560d2-0\" class=\"displacy\" width=\"3950\" height=\"662.0\" direction=\"ltr\" style=\"max-width: none; height: 662.0px; color: blue; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Dorothy</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"200\">lived</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"200\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"350\">in</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"350\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"650\">midst</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"650\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"800\">of</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"800\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1100\">great</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1100\">ADJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1250\">Kansas</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1250\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1400\">prairies,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1400\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1550\">with</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1550\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1700\">Uncle</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1700\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1850\">Harry,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1850\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2000\">who</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2000\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2150\">was</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2150\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2300\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2300\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2450\">farmer,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2450\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2600\">and</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2600\">CCONJ</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2750\">Aunt</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2750\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"2900\">Em,</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"2900\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3050\">who</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3050\">PRON</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3200\">was</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3200\">AUX</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3350\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3350\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3500\">farmer</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3500\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3650\">'s</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3650\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"572.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"3800\">wife.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"3800\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-0\" stroke-width=\"2px\" d=\"M62,527.0 62,502.0 182.0,502.0 182.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M62,529.0 L58,521.0 66,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-1\" stroke-width=\"2px\" d=\"M212,527.0 212,502.0 332.0,502.0 332.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M332.0,529.0 L336.0,521.0 328.0,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-2\" stroke-width=\"2px\" d=\"M512,527.0 512,502.0 632.0,502.0 632.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M512,529.0 L508,521.0 516,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-3\" stroke-width=\"2px\" d=\"M362,527.0 362,477.0 635.0,477.0 635.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M635.0,529.0 L639.0,521.0 631.0,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-4\" stroke-width=\"2px\" d=\"M662,527.0 662,502.0 782.0,502.0 782.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M782.0,529.0 L786.0,521.0 778.0,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-5\" stroke-width=\"2px\" d=\"M962,527.0 962,452.0 1388.0,452.0 1388.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M962,529.0 L958,521.0 966,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-6\" stroke-width=\"2px\" d=\"M1112,527.0 1112,477.0 1385.0,477.0 1385.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">amod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1112,529.0 L1108,521.0 1116,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-7\" stroke-width=\"2px\" d=\"M1262,527.0 1262,502.0 1382.0,502.0 1382.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1262,529.0 L1258,521.0 1266,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-8\" stroke-width=\"2px\" d=\"M812,527.0 812,427.0 1391.0,427.0 1391.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1391.0,529.0 L1395.0,521.0 1387.0,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-9\" stroke-width=\"2px\" d=\"M212,527.0 212,352.0 1550.0,352.0 1550.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1550.0,529.0 L1554.0,521.0 1546.0,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-10\" stroke-width=\"2px\" d=\"M1712,527.0 1712,502.0 1832.0,502.0 1832.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1712,529.0 L1708,521.0 1716,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-11\" stroke-width=\"2px\" d=\"M1562,527.0 1562,477.0 1835.0,477.0 1835.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-11\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1835.0,529.0 L1839.0,521.0 1831.0,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-12\" stroke-width=\"2px\" d=\"M2012,527.0 2012,502.0 2132.0,502.0 2132.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-12\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2012,529.0 L2008,521.0 2016,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-13\" stroke-width=\"2px\" d=\"M1862,527.0 1862,477.0 2135.0,477.0 2135.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-13\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2135.0,529.0 L2139.0,521.0 2131.0,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-14\" stroke-width=\"2px\" d=\"M2312,527.0 2312,502.0 2432.0,502.0 2432.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-14\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2312,529.0 L2308,521.0 2316,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-15\" stroke-width=\"2px\" d=\"M2162,527.0 2162,477.0 2435.0,477.0 2435.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-15\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2435.0,529.0 L2439.0,521.0 2431.0,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-16\" stroke-width=\"2px\" d=\"M1862,527.0 1862,402.0 2594.0,402.0 2594.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-16\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">cc</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2594.0,529.0 L2598.0,521.0 2590.0,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-17\" stroke-width=\"2px\" d=\"M2762,527.0 2762,502.0 2882.0,502.0 2882.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-17\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2762,529.0 L2758,521.0 2766,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-18\" stroke-width=\"2px\" d=\"M1862,527.0 1862,377.0 2897.0,377.0 2897.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-18\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">conj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M2897.0,529.0 L2901.0,521.0 2893.0,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-19\" stroke-width=\"2px\" d=\"M3062,527.0 3062,502.0 3182.0,502.0 3182.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-19\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3062,529.0 L3058,521.0 3066,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-20\" stroke-width=\"2px\" d=\"M2912,527.0 2912,477.0 3185.0,477.0 3185.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-20\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">relcl</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3185.0,529.0 L3189.0,521.0 3181.0,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-21\" stroke-width=\"2px\" d=\"M3362,527.0 3362,502.0 3482.0,502.0 3482.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-21\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3362,529.0 L3358,521.0 3366,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-22\" stroke-width=\"2px\" d=\"M3512,527.0 3512,477.0 3785.0,477.0 3785.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-22\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">poss</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3512,529.0 L3508,521.0 3516,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-23\" stroke-width=\"2px\" d=\"M3512,527.0 3512,502.0 3632.0,502.0 3632.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-23\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">case</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3632.0,529.0 L3636.0,521.0 3628.0,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-24\" stroke-width=\"2px\" d=\"M3212,527.0 3212,427.0 3791.0,427.0 3791.0,527.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-1a3582c6dc754b9b8b0b74daf5b560d2-0-24\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">attr</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M3791.0,529.0 L3795.0,521.0 3787.0,521.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdHEVOEVMHl8"
      },
      "source": [
        "A shorter sentence for a clearer understanding of dependancy parsing\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZ-XieBbvzzI",
        "outputId": "fe006875-5f9a-49fd-ec99-22d75eb1553d"
      },
      "source": [
        "doc = nlp(\"The dog walked up the hill.\")\n",
        "[(token.text, token.dep_) for token in doc]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'det'),\n",
              " ('dog', 'nsubj'),\n",
              " ('walked', 'ROOT'),\n",
              " ('up', 'prep'),\n",
              " ('the', 'det'),\n",
              " ('hill', 'pobj'),\n",
              " ('.', 'punct')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "A7KobsQo7_gi",
        "outputId": "3c0f19ac-e871-4c64-aa19-a85c4ec3408e"
      },
      "source": [
        "doc = nlp(\"The dog walked up the hill.\")\n",
        "displacy.render(doc, style=\"dep\", jupyter=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"e75f1a1785344bfeb87ed0a14c9892c0-0\" class=\"displacy\" width=\"1100\" height=\"312.0\" direction=\"ltr\" style=\"max-width: none; height: 312.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">The</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"225\">dog</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"225\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"400\">walked</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"400\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"575\">up</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"575\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"750\">the</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"750\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"222.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"925\">hill.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"925\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e75f1a1785344bfeb87ed0a14c9892c0-0-0\" stroke-width=\"2px\" d=\"M70,177.0 C70,89.5 220.0,89.5 220.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e75f1a1785344bfeb87ed0a14c9892c0-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,179.0 L62,167.0 78,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e75f1a1785344bfeb87ed0a14c9892c0-0-1\" stroke-width=\"2px\" d=\"M245,177.0 C245,89.5 395.0,89.5 395.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e75f1a1785344bfeb87ed0a14c9892c0-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M245,179.0 L237,167.0 253,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e75f1a1785344bfeb87ed0a14c9892c0-0-2\" stroke-width=\"2px\" d=\"M420,177.0 C420,89.5 570.0,89.5 570.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e75f1a1785344bfeb87ed0a14c9892c0-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M570.0,179.0 L578.0,167.0 562.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e75f1a1785344bfeb87ed0a14c9892c0-0-3\" stroke-width=\"2px\" d=\"M770,177.0 C770,89.5 920.0,89.5 920.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e75f1a1785344bfeb87ed0a14c9892c0-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770,179.0 L762,167.0 778,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-e75f1a1785344bfeb87ed0a14c9892c0-0-4\" stroke-width=\"2px\" d=\"M595,177.0 C595,2.0 925.0,2.0 925.0,177.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-e75f1a1785344bfeb87ed0a14c9892c0-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M925.0,179.0 L933.0,167.0 917.0,167.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pv_rNMGjLujl"
      },
      "source": [
        "### Ner - Named entity recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "R46GTPWw9JIf",
        "outputId": "1af85203-fb08-44f7-e695-aff9bce8ba4e"
      },
      "source": [
        "for entity in doc_oz.ents:\n",
        "  print(entity.text + ' - ' + entity.label_ + ' - ' + str(spacy.explain(entity.label_)))\n",
        "displacy.render(doc_oz, style=\"ent\", jupyter=True)\n",
        "# As you can see, Dorothy is not considered an ner"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Kansas - GPE - Countries, cities, states\n",
            "Uncle Harry - PERSON - People, including fictional\n",
            "Aunt Em - PERSON - People, including fictional\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Dorothy lived in the midst of the great \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Kansas\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " prairies, with \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Uncle Harry\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", who was a farmer, and \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Aunt Em\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ", who was the farmer's wife.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wNLLWyaTM8-C"
      },
      "source": [
        "doc_two had more entities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "id": "AYT-8_4B9ZvC",
        "outputId": "cf657cde-b397-48d5-a453-a0e0ed299c71"
      },
      "source": [
        "for entity in doc_two.ents:\n",
        "    print(entity.text + ' - ' + entity.label_ + ' - ' + str(spacy.explain(entity.label_)))\n",
        "displacy.render(doc_two, style=\"ent\", jupyter=True)\n",
        "# A tale of two cities should be a work of art"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Bible - WORK_OF_ART - Titles of books, songs, etc.\n",
            "Two - CARDINAL - Numerals that do not fall under another type\n",
            "Charles Dickens - PERSON - People, including fictional\n",
            "first - ORDINAL - \"first\", \"second\", etc.\n",
            "1859 - DATE - Absolute or relative dates or periods\n",
            "London - GPE - Countries, cities, states\n",
            "Paris - GPE - Countries, cities, states\n",
            "the French Revolution - EVENT - Named hurricanes, battles, wars, sports events, etc.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">The \n",
              "<mark class=\"entity\" style=\"background: #f0d0ff; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Bible\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">WORK_OF_ART</span>\n",
              "</mark>\n",
              " is a religious book. A Tale of \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Two\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">CARDINAL</span>\n",
              "</mark>\n",
              " Cities was written by \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Charles Dickens\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    first\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORDINAL</span>\n",
              "</mark>\n",
              " published in \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    1859\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ". It is set in \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    London\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " and \n",
              "<mark class=\"entity\" style=\"background: #feca74; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Paris\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">GPE</span>\n",
              "</mark>\n",
              " before and during \n",
              "<mark class=\"entity\" style=\"background: #ffeb80; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    the French Revolution\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">EVENT</span>\n",
              "</mark>\n",
              ".</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQupAeIVU9ra"
      },
      "source": [
        "**Bonus:** _Try to find some other named entities (eg- nationalities, non-GPE locations, languages, time, money, quantity and percent)_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "s50q3ehUV2ox",
        "outputId": "65a3701f-40b2-4000-8ff2-15c0299e2f0b"
      },
      "source": [
        "doc_ent=nlp(\"\")\n",
        "\n",
        "for ent in doc_ent.ents:\n",
        "  print(entity.text + ' - ' + entity.label_ + ' - ' + str(spacy.explain(entity.label_)))\n",
        "displacy.render(doc_ent, style=\"ent\", jupyter=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\"></div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjp6T47RNVng"
      },
      "source": [
        "## Adding custom pipe components"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ocnly6HKNesf"
      },
      "source": [
        "###Custom Pipeline for ',' sentence boundary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-QTNTYL-CrW"
      },
      "source": [
        "def set_custom_boundaries(doc):\n",
        "    for token in doc[:-1]:\n",
        "        if token.text == \",\":\n",
        "          # if the current token is a comma, \n",
        "          # the next token should be considered the start of a sentence\n",
        "            doc[token.i+1].is_sent_start = True\n",
        "    return doc\n",
        "\n",
        "nlp_custom = spacy.load(\"en\")\n",
        "nlp_custom.add_pipe(set_custom_boundaries, before=\"parser\")\n",
        "# Why do you think I put set_custom_boundaries before the parser?"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0vwkPTVA-gm",
        "outputId": "f74dfa66-8811-4a72-90a1-d45e238c7f15"
      },
      "source": [
        "doc_cities = nlp(\"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us, we were all going direct to Heaven, we were all going direct the other way—in short, the period was so far like the present period, that some of its noisiest authorities insisted on its being received, for good or for evil, in the superlative degree of comparison only.\")\n",
        "doc_cities_custom = nlp_custom(\"It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us, we were all going direct to Heaven, we were all going direct the other way—in short, the period was so far like the present period, that some of its noisiest authorities insisted on its being received, for good or for evil, in the superlative degree of comparison only.\")\n",
        "\n",
        "print(\"WITHOUT CUSTOM: \")\n",
        "for sent in doc_cities.sents:\n",
        "  print(sent.text)\n",
        "print(\"------------------------\")\n",
        "print(\"WITH CUSTOM: \")\n",
        "for sent in doc_cities_custom.sents:\n",
        "  print(sent.text)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WITHOUT CUSTOM: \n",
            "It was the best of times, it was the worst of times, it was the age of wisdom, it was the age of foolishness, it was the epoch of belief, it was the epoch of incredulity, it was the season of Light, it was the season of Darkness, it was the spring of hope, it was the winter of despair, we had everything before us, we had nothing before us, we were all going direct to Heaven, we were all going direct the other way—in short, the period was so far like the present period, that some of its noisiest authorities insisted on its being received, for good or for evil, in the superlative degree of comparison only.\n",
            "------------------------\n",
            "WITH CUSTOM: \n",
            "It was the best of times,\n",
            "it was the worst of times,\n",
            "it was the age of wisdom,\n",
            "it was the age of foolishness,\n",
            "it was the epoch of belief,\n",
            "it was the epoch of incredulity,\n",
            "it was the season of Light,\n",
            "it was the season of Darkness,\n",
            "it was the spring of hope,\n",
            "it was the winter of despair,\n",
            "we had everything before us,\n",
            "we had nothing before us,\n",
            "we were all going direct to Heaven,\n",
            "we were all going direct the other way—in short,\n",
            "the period was so far like the present period,\n",
            "that some of its noisiest authorities insisted on its being received,\n",
            "for good or for evil,\n",
            "in the superlative degree of comparison only.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDPLl_nkNpU5"
      },
      "source": [
        "## Comparing similarities"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZzKz2QrZ6ml"
      },
      "source": [
        "We need to load the larger model to do comparison. This can take 3-5 minutes. You may need to restart the kernel afterwards (Runtime -> Restart runtime or ctrl+M)\n",
        "\n",
        "You can also use the medium model if you wish. Simply comment out the first line and remove the '#' before the second."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRVnmyH2CQ15",
        "outputId": "80f898c5-d320-4ff5-d85e-30462c1d6c29"
      },
      "source": [
        " !python -m spacy download en_core_web_lg\n",
        "\n",
        "# !python -m spacy download en_core_web_md"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_lg==2.2.5 from https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-2.2.5/en_core_web_lg-2.2.5.tar.gz#egg=en_core_web_lg==2.2.5 in /usr/local/lib/python3.6/dist-packages (2.2.5)\n",
            "Requirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from en_core_web_lg==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (50.3.2)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (1.0.4)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2020.11.8)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_lg==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_lg==2.2.5) (3.4.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tuSu-J2POOIm"
      },
      "source": [
        "If you had to restart the kernel/runtime, remove the '#' before two import statements (first two sentences)\n",
        "\n",
        "If you downloaded the medium model, comment out third line and un-comment the last line"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycimZ0ArELTL"
      },
      "source": [
        "# import spacy\n",
        "# from spacy import displacy\n",
        "\n",
        "nlp = spacy.load('en_core_web_lg')\n",
        "\n",
        "# nlp = spacy.load('en_core_web_md')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPZInnr9V2RY",
        "outputId": "282aaa73-4a70-4b41-f242-8fbee1e6886f"
      },
      "source": [
        "nlp.vocab.length"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1340241"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CnVPz39vOsOb"
      },
      "source": [
        "oov stands for out of vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvXrz3h5C6R_",
        "outputId": "eb518790-ca8b-4dad-afff-22a188e52018"
      },
      "source": [
        "tokens = nlp(\"apple dog broken banana cat onomatopoeia asdfkj\")\n",
        "# asdfkj is a variant of \"keyboard smashing\" - a phenomenon which is seen on most social media\n",
        "for token in tokens:\n",
        "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "apple True 7.1346846 False\n",
            "dog True 7.0336733 False\n",
            "broken True 5.5968375 False\n",
            "banana True 6.700014 False\n",
            "cat True 6.6808186 False\n",
            "onomatopoeia True 6.8262777 False\n",
            "asdfkj False 0.0 True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lU48_tsvO2Xy"
      },
      "source": [
        "You may get errors as 'asdfkj' does not have a vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbZinp_kDxM1",
        "outputId": "07a63274-4d99-4860-d6ef-e4a35848909d"
      },
      "source": [
        "for tok1 in tokens:\n",
        "    for tok2 in tokens:\n",
        "        print(tok1.text, tok2.text, tok1.similarity(tok2))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "apple apple 1.0\n",
            "apple dog 0.26339024\n",
            "apple broken 0.30717567\n",
            "apple banana 0.5831845\n",
            "apple cat 0.28213844\n",
            "apple onomatopoeia 0.04173978\n",
            "apple asdfkj 0.0\n",
            "dog apple 0.26339024\n",
            "dog dog 1.0\n",
            "dog broken 0.2948628\n",
            "dog banana 0.24327643\n",
            "dog cat 0.80168545\n",
            "dog onomatopoeia 0.020367466\n",
            "dog asdfkj 0.0\n",
            "broken apple 0.30717567\n",
            "broken dog 0.2948628\n",
            "broken broken 1.0\n",
            "broken banana 0.2577424\n",
            "broken cat 0.30218005\n",
            "broken onomatopoeia -0.06426965\n",
            "broken asdfkj 0.0\n",
            "banana apple 0.5831845\n",
            "banana dog 0.24327643\n",
            "banana broken 0.2577424\n",
            "banana banana 1.0\n",
            "banana cat 0.28154364\n",
            "banana onomatopoeia 0.04627617\n",
            "banana asdfkj 0.0\n",
            "cat apple 0.28213844\n",
            "cat dog 0.80168545\n",
            "cat broken 0.30218005\n",
            "cat banana 0.28154364\n",
            "cat cat 1.0\n",
            "cat onomatopoeia 0.04033484\n",
            "cat asdfkj 0.0\n",
            "onomatopoeia apple 0.04173978\n",
            "onomatopoeia dog 0.020367466\n",
            "onomatopoeia broken -0.06426965\n",
            "onomatopoeia banana 0.04627617\n",
            "onomatopoeia cat 0.04033484\n",
            "onomatopoeia onomatopoeia 1.0\n",
            "onomatopoeia asdfkj 0.0\n",
            "asdfkj apple 0.0\n",
            "asdfkj dog 0.0\n",
            "asdfkj broken 0.0\n",
            "asdfkj banana 0.0\n",
            "asdfkj cat 0.0\n",
            "asdfkj onomatopoeia 0.0\n",
            "asdfkj asdfkj 1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n",
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W008] Evaluating Token.similarity based on empty vectors.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SvhFpHhO7LT"
      },
      "source": [
        "Try it on your own data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkU8C8kqFCoZ",
        "outputId": "8e519ea5-b603-4533-9293-47524b9d91fb"
      },
      "source": [
        "doc_1 = nlp(\"\")\n",
        "doc_2 = nlp(\"\")\n",
        "doc_1.similarity(doc_2)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwTfKZFCFwwI"
      },
      "source": [
        "## Custom Pipeline: Training the model on new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eVbC31f5mrX"
      },
      "source": [
        "# We will train nlp_train\n",
        "nlp_train = spacy.load('en_core_web_lg')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpgNjTNuGAxr"
      },
      "source": [
        "Let's test the ner capabilities once again"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123
        },
        "id": "62cgBoTQF3dQ",
        "outputId": "a23dbdf5-23b9-493e-b7a1-163d7363a603"
      },
      "source": [
        "doc = nlp(\"Fridge need to be replaced ASAP. Dorothy has a dog named Toto. Horses are tall.\")\n",
        "for ent in doc.ents:\n",
        "  print(ent.text, ent.label_)\n",
        "displacy.render(doc, style=\"ent\", jupyter=True)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dorothy PERSON\n",
            "Toto PERSON\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Fridge need to be replaced ASAP. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Dorothy\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has a dog named \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Toto\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ". Horses are tall.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWUJNhRsGhHR"
      },
      "source": [
        "We'll attempt to teach spaCy how to identify products and animals.\n",
        "\n",
        "**Note:** *This is not a good example of training data. Good data is larger and more diverse.*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FaG7mK2TGdb0"
      },
      "source": [
        "TRAINING_DATA=[\n",
        "               # format is  (\"your_string\", {\"entities:[(start_index, end_index, \"type\")]}),\n",
        "               # the first letter of your_string is at index 0\n",
        "               # this code only works for one entity per sentence for simplicity\n",
        "    (\"I left Vellore yesterday.\", {\"entities\": [(7, 14, \"GPE\")]}),\n",
        "    (\"I need to buy more clothes.\", {\"entities\": [(19, 26, \"PRODUCT\")]}),\n",
        "    (\"I rented a house.\", {\"entities\": [(11, 16, \"PRODUCT\")]}),\n",
        "    (\"Fridge needs to be replaced ASAP \", {\"entities\": [(0,6, \"PRODUCT\")]}),\n",
        "    (\"Fridge can be ordered in Amazon \", {\"entities\": [(0,6, \"PRODUCT\")]}),\n",
        "    (\"There has been severe flooding in North India\", {\"entities\": [(34, 45, \"GPE\")]}),\n",
        "    (\"I got my truck stolen\", {\"entities\": [(9,14, \"PRODUCT\")]}),\n",
        "    (\"Aprajita orders clothes from amazon\", {\"entities\": [(0,8, \"PERSON\")]}),\n",
        "    (\"I recently ordered from Shoppers Stop\", {\"entities\": [(24,37,\"ORG\")]}),\n",
        "    (\"I bought a new bicycle\", {\"entities\": [(15,22, \"PRODUCT\")]}),\n",
        "    (\"I donated my old toys\", {\"entities\": [(17,21, \"PRODUCT\")]}),\n",
        "    (\"I bought a fancy new watch\", {\"entities\": [(21,26, \"PRODUCT\")]}),\n",
        "    (\"I rented a cabin for our vacation\", {\"entities\": [(11,16, \"PRODUCT\")]}),\n",
        "    (\"I borrowed a ball from our neighbour\", {\"entities\": [(13,17, \"PRODUCT\")]}),\n",
        "    (\"I repaired my car\", {\"entities\": [(14,17, \"PRODUCT\")]}),\n",
        "    (\"I got my computer fixed\", {\"entities\": [(9,17, \"PRODUCT\")]}),\n",
        "    (\"Richa is starting school today\", {\"entities\":[(0,5,\"PERSON\")]}),\n",
        "    (\"They adopted a boy named Amar\", {\"entities\":[(25, 29,\"PERSON\")]}),\n",
        "    (\"Sanjay Dutt released a new film\", {\"entities\":[(0,11,\"PERSON\")]}),\n",
        "    (\"Horses are too tall and they will hurt your feelings\", {\"entities\":[(0, 6, \"ANIMAL\")]}),\n",
        "    (\"I want a dog\", {\"entities\":[(9,12,\"ANIMAL\")]}),\n",
        "    (\"Cats are known to be evil\", {\"entities\":[(0,4,\"ANIMAL\")]}),\n",
        "    (\"I saw a bird today\", {\"entities\":[(8, 12, \"ANIMAL\")]}),\n",
        "    (\"Snoopy is a dog\", {\"entities\":[(12,15,\"ANIMAL\")]}),\n",
        "    (\"Rio is a movie about birds\", {\"entities\":[(21, 26,\"ANIMAL\")]}),\n",
        "    (\"Dogs should not eat chocolate\", {\"entities\":[(0,4,\"ANIMALS\")]}),\n",
        "    (\"Cows give milk\", {\"entities\":[(0,4,\"ANIMALS\")]}),\n",
        "    (\"Goats eat grass\", {\"entities\":[(0, 5, \"ANIMALS\")]}),\n",
        "    (\"I do not buy Donkeys on Amazon\", {\"entities\":[(13, 20, \"ANIMALS\")]}),\n",
        "    (\"Tigers are predators\", {\"entities\":[(0, 6, \"ANIMALS\")]}),\n",
        "    (\"Rachna uses Amazon regularly\", {\"entities\":[(0,6,\"PERSON\")]}),\n",
        "    (\"Archana uses Flipkart to order clothes\", {\"entities\":[(0, 7, \"PERSON\")]}),\n",
        "    (\"Aparna has a purse\", {\"entities\":[(0, 6, \"PERSON\")]})\n",
        "   ]"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_0TmTx8HZVV"
      },
      "source": [
        "# Storing the ner pipeline as a variable for easy access\n",
        "ner = nlp_train.get_pipe(\"ner\")"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_17S9lK1HovO"
      },
      "source": [
        "We need to add the new labels to ner."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqas4lT9HeJW"
      },
      "source": [
        "for _, annotations in TRAINING_DATA:\n",
        "    for ent in annotations.get(\"entities\"):\n",
        "      # the second part of the entity is the label. \n",
        "      # labels that are already present won't be added\n",
        "        ner.add_label(ent[2])"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4l8Eh5zPkaE"
      },
      "source": [
        "Disable the pipeline components that should not be changed"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HhX3r9AHwrd"
      },
      "source": [
        "# pipe_exc includes pipeline components that we want to change\n",
        "pipe_exc = [\"ner\", \"trf_wordpiecer\", \"trf_tok2vec\"]\n",
        "disabled_pipes = [pipe for pipe in nlp_train.pipe_names if pipe not in pipe_exc]\n",
        "# disabled_pipes includes tokenizer, tagger and parser"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "243HrW7qHz-O"
      },
      "source": [
        "# We need random to randomize input, minibatch to create minibatches of text data, compouding func to yield an infinite series of compouding values\n",
        "import random\n",
        "from spacy.util import minibatch, compounding\n",
        "from pathlib import Path"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1bG00ePPpk_"
      },
      "source": [
        "## Training the model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FHGQBY-NY88g"
      },
      "source": [
        "This may take a couple of minutes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgrAgBGpH57o",
        "outputId": "bc193219-d2b9-4b2b-a7c4-bc22210de81d"
      },
      "source": [
        "with nlp_train.disable_pipes(*disabled_pipes):\n",
        "\n",
        "  # Training for 180 iterations\n",
        "  for iteration in range(180):\n",
        "\n",
        "    # shuffling examples  before every iteration\n",
        "    random.shuffle(TRAINING_DATA)\n",
        "    losses = {}\n",
        "    # batch up the examples using spaCy's minibatch\n",
        "    batches = minibatch(TRAINING_DATA, size=compounding(4.0, 32.0, 1.001))\n",
        "    for batch in batches:\n",
        "        texts, annotations = zip(*batch)\n",
        "        nlp_train.update(\n",
        "                    texts,  # batch of texts\n",
        "                    annotations,  # batch of annotations\n",
        "                    drop=0.5,  # dropout - make it harder to memorise data\n",
        "                    losses=losses,\n",
        "                )\n",
        "        print(\"Losses\", losses)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Losses {'ner': 25.80991291999817}\n",
            "Losses {'ner': 55.057631969451904}\n",
            "Losses {'ner': 82.3158814907074}\n",
            "Losses {'ner': 107.46443819999695}\n",
            "Losses {'ner': 131.09159231185913}\n",
            "Losses {'ner': 154.8016436100006}\n",
            "Losses {'ner': 171.26841616630554}\n",
            "Losses {'ner': 192.00530004501343}\n",
            "Losses {'ner': 193.98279032099185}\n",
            "Losses {'ner': 24.513182520866394}\n",
            "Losses {'ner': 42.650454223155975}\n",
            "Losses {'ner': 67.68861073255539}\n",
            "Losses {'ner': 95.73404043912888}\n",
            "Losses {'ner': 122.27933818101883}\n",
            "Losses {'ner': 148.3598888516426}\n",
            "Losses {'ner': 174.05323773622513}\n",
            "Losses {'ner': 197.3733792901039}\n",
            "Losses {'ner': 203.11729405422557}\n",
            "Losses {'ner': 16.88648808002472}\n",
            "Losses {'ner': 41.96008884906769}\n",
            "Losses {'ner': 69.14534389972687}\n",
            "Losses {'ner': 90.61756098270416}\n",
            "Losses {'ner': 106.46225643157959}\n",
            "Losses {'ner': 132.0712844133377}\n",
            "Losses {'ner': 156.8713639974594}\n",
            "Losses {'ner': 173.17460453510284}\n",
            "Losses {'ner': 180.69876942038536}\n",
            "Losses {'ner': 21.526761770248413}\n",
            "Losses {'ner': 44.38239645957947}\n",
            "Losses {'ner': 63.60519540309906}\n",
            "Losses {'ner': 90.25893104076385}\n",
            "Losses {'ner': 113.41856682300568}\n",
            "Losses {'ner': 133.5736130475998}\n",
            "Losses {'ner': 153.07965099811554}\n",
            "Losses {'ner': 177.72159111499786}\n",
            "Losses {'ner': 182.32172969728708}\n",
            "Losses {'ner': 21.078866481781006}\n",
            "Losses {'ner': 42.56339168548584}\n",
            "Losses {'ner': 66.35387349128723}\n",
            "Losses {'ner': 94.738600730896}\n",
            "Losses {'ner': 116.20070838928223}\n",
            "Losses {'ner': 137.51650547981262}\n",
            "Losses {'ner': 153.93941044807434}\n",
            "Losses {'ner': 175.2839958667755}\n",
            "Losses {'ner': 178.53456580638885}\n",
            "Losses {'ner': 16.58414316177368}\n",
            "Losses {'ner': 34.74976706504822}\n",
            "Losses {'ner': 52.82062029838562}\n",
            "Losses {'ner': 75.38490641117096}\n",
            "Losses {'ner': 95.47806799411774}\n",
            "Losses {'ner': 109.29823471605778}\n",
            "Losses {'ner': 127.81495286524296}\n",
            "Losses {'ner': 148.96721769869328}\n",
            "Losses {'ner': 154.04883606731892}\n",
            "Losses {'ner': 13.539018392562866}\n",
            "Losses {'ner': 37.41132164001465}\n",
            "Losses {'ner': 56.77949285507202}\n",
            "Losses {'ner': 72.82775163650513}\n",
            "Losses {'ner': 94.16840410232544}\n",
            "Losses {'ner': 110.7105450630188}\n",
            "Losses {'ner': 130.27144598960876}\n",
            "Losses {'ner': 151.12072134017944}\n",
            "Losses {'ner': 156.00037598982453}\n",
            "Losses {'ner': 20.566909790039062}\n",
            "Losses {'ner': 37.27609717845917}\n",
            "Losses {'ner': 59.63565909862518}\n",
            "Losses {'ner': 72.6292964220047}\n",
            "Losses {'ner': 93.95837771892548}\n",
            "Losses {'ner': 111.52817678451538}\n",
            "Losses {'ner': 136.10348868370056}\n",
            "Losses {'ner': 156.40951013565063}\n",
            "Losses {'ner': 161.81497113220394}\n",
            "Losses {'ner': 19.66868495941162}\n",
            "Losses {'ner': 35.537739753723145}\n",
            "Losses {'ner': 54.18539810180664}\n",
            "Losses {'ner': 74.02014470100403}\n",
            "Losses {'ner': 95.38411664962769}\n",
            "Losses {'ner': 110.01013493537903}\n",
            "Losses {'ner': 125.90818238258362}\n",
            "Losses {'ner': 144.4586889743805}\n",
            "Losses {'ner': 150.5767177194357}\n",
            "Losses {'ner': 20.145288228988647}\n",
            "Losses {'ner': 34.63475513458252}\n",
            "Losses {'ner': 55.438281774520874}\n",
            "Losses {'ner': 76.90602612495422}\n",
            "Losses {'ner': 94.28045153617859}\n",
            "Losses {'ner': 112.35816404223442}\n",
            "Losses {'ner': 135.53641292452812}\n",
            "Losses {'ner': 154.73407074809074}\n",
            "Losses {'ner': 159.89596810936928}\n",
            "Losses {'ner': 22.918174743652344}\n",
            "Losses {'ner': 40.34100425243378}\n",
            "Losses {'ner': 54.01208829879761}\n",
            "Losses {'ner': 65.56840062141418}\n",
            "Losses {'ner': 78.5128231048584}\n",
            "Losses {'ner': 97.17693209648132}\n",
            "Losses {'ner': 121.56677055358887}\n",
            "Losses {'ner': 137.8017508983612}\n",
            "Losses {'ner': 139.77527281292714}\n",
            "Losses {'ner': 18.15599751472473}\n",
            "Losses {'ner': 34.98952877521515}\n",
            "Losses {'ner': 50.43720984458923}\n",
            "Losses {'ner': 65.1823273897171}\n",
            "Losses {'ner': 87.54503643512726}\n",
            "Losses {'ner': 108.4842301607132}\n",
            "Losses {'ner': 122.55122244358063}\n",
            "Losses {'ner': 141.80957448482513}\n",
            "Losses {'ner': 147.27989095449448}\n",
            "Losses {'ner': 22.70004892349243}\n",
            "Losses {'ner': 49.628498792648315}\n",
            "Losses {'ner': 65.0688087940216}\n",
            "Losses {'ner': 80.32187008857727}\n",
            "Losses {'ner': 91.98050907254219}\n",
            "Losses {'ner': 110.93289545178413}\n",
            "Losses {'ner': 123.69816353917122}\n",
            "Losses {'ner': 139.7789069712162}\n",
            "Losses {'ner': 146.09029491059482}\n",
            "Losses {'ner': 16.623663067817688}\n",
            "Losses {'ner': 28.12640556693077}\n",
            "Losses {'ner': 40.17192503809929}\n",
            "Losses {'ner': 59.164347141981125}\n",
            "Losses {'ner': 82.42606446146965}\n",
            "Losses {'ner': 101.68104907870293}\n",
            "Losses {'ner': 114.74911186099052}\n",
            "Losses {'ner': 128.93243405222893}\n",
            "Losses {'ner': 131.97691583260894}\n",
            "Losses {'ner': 15.038521409034729}\n",
            "Losses {'ner': 36.80484974384308}\n",
            "Losses {'ner': 51.43128490447998}\n",
            "Losses {'ner': 65.50101420283318}\n",
            "Losses {'ner': 81.99457642436028}\n",
            "Losses {'ner': 100.39078018069267}\n",
            "Losses {'ner': 112.37854132056236}\n",
            "Losses {'ner': 127.31434568762779}\n",
            "Losses {'ner': 129.17428171331994}\n",
            "Losses {'ner': 21.687004566192627}\n",
            "Losses {'ner': 35.69874835014343}\n",
            "Losses {'ner': 52.92693591117859}\n",
            "Losses {'ner': 68.05582928657532}\n",
            "Losses {'ner': 79.10611379146576}\n",
            "Losses {'ner': 90.64418029785156}\n",
            "Losses {'ner': 106.93039834499359}\n",
            "Losses {'ner': 128.61604607105255}\n",
            "Losses {'ner': 129.7021827311255}\n",
            "Losses {'ner': 16.039668321609497}\n",
            "Losses {'ner': 32.57246494293213}\n",
            "Losses {'ner': 49.91970753669739}\n",
            "Losses {'ner': 66.9457882642746}\n",
            "Losses {'ner': 83.18325626850128}\n",
            "Losses {'ner': 99.98844516277313}\n",
            "Losses {'ner': 117.03448593616486}\n",
            "Losses {'ner': 133.82557213306427}\n",
            "Losses {'ner': 138.7608174085617}\n",
            "Losses {'ner': 12.962374806404114}\n",
            "Losses {'ner': 25.389836698770523}\n",
            "Losses {'ner': 41.03388884663582}\n",
            "Losses {'ner': 63.45658114552498}\n",
            "Losses {'ner': 77.60628393292427}\n",
            "Losses {'ner': 96.37859204411507}\n",
            "Losses {'ner': 107.47838693857193}\n",
            "Losses {'ner': 122.65677434206009}\n",
            "Losses {'ner': 125.81878202241205}\n",
            "Losses {'ner': 16.230735301971436}\n",
            "Losses {'ner': 34.71559000015259}\n",
            "Losses {'ner': 59.09207606315613}\n",
            "Losses {'ner': 73.35184824466705}\n",
            "Losses {'ner': 92.27568757534027}\n",
            "Losses {'ner': 113.78049230575562}\n",
            "Losses {'ner': 133.395268201828}\n",
            "Losses {'ner': 151.8452934026718}\n",
            "Losses {'ner': 155.6456277370453}\n",
            "Losses {'ner': 17.06213140487671}\n",
            "Losses {'ner': 30.30479395389557}\n",
            "Losses {'ner': 42.39569926261902}\n",
            "Losses {'ner': 60.39514112472534}\n",
            "Losses {'ner': 80.07072567939758}\n",
            "Losses {'ner': 97.02384114265442}\n",
            "Losses {'ner': 112.91468739509583}\n",
            "Losses {'ner': 133.97946572303772}\n",
            "Losses {'ner': 136.35759093583837}\n",
            "Losses {'ner': 19.58025074005127}\n",
            "Losses {'ner': 27.83015513420105}\n",
            "Losses {'ner': 46.67011308670044}\n",
            "Losses {'ner': 63.85081243515015}\n",
            "Losses {'ner': 82.47096085548401}\n",
            "Losses {'ner': 99.96979320049286}\n",
            "Losses {'ner': 113.96860373020172}\n",
            "Losses {'ner': 132.20463383197784}\n",
            "Losses {'ner': 134.69859274476767}\n",
            "Losses {'ner': 15.214221596717834}\n",
            "Losses {'ner': 31.94484281539917}\n",
            "Losses {'ner': 48.810781717300415}\n",
            "Losses {'ner': 62.58560132980347}\n",
            "Losses {'ner': 81.31216406822205}\n",
            "Losses {'ner': 95.11648297309875}\n",
            "Losses {'ner': 109.46662127971649}\n",
            "Losses {'ner': 124.16740715503693}\n",
            "Losses {'ner': 127.61886248923838}\n",
            "Losses {'ner': 21.27663016319275}\n",
            "Losses {'ner': 37.77895450592041}\n",
            "Losses {'ner': 50.916847586631775}\n",
            "Losses {'ner': 66.11316311359406}\n",
            "Losses {'ner': 85.06043636798859}\n",
            "Losses {'ner': 95.19616198539734}\n",
            "Losses {'ner': 114.33399772644043}\n",
            "Losses {'ner': 130.90763068199158}\n",
            "Losses {'ner': 133.04670445621014}\n",
            "Losses {'ner': 17.205439925193787}\n",
            "Losses {'ner': 34.41426455974579}\n",
            "Losses {'ner': 51.19129824638367}\n",
            "Losses {'ner': 69.14322996139526}\n",
            "Losses {'ner': 84.7188549041748}\n",
            "Losses {'ner': 97.59504953026772}\n",
            "Losses {'ner': 115.25595751404762}\n",
            "Losses {'ner': 137.7062956392765}\n",
            "Losses {'ner': 142.0855989791453}\n",
            "Losses {'ner': 22.915974140167236}\n",
            "Losses {'ner': 40.258246421813965}\n",
            "Losses {'ner': 55.62435972690582}\n",
            "Losses {'ner': 72.90300786495209}\n",
            "Losses {'ner': 88.07659494876862}\n",
            "Losses {'ner': 98.88758289813995}\n",
            "Losses {'ner': 108.80394718050957}\n",
            "Losses {'ner': 129.6974215209484}\n",
            "Losses {'ner': 134.1299845741596}\n",
            "Losses {'ner': 15.096140146255493}\n",
            "Losses {'ner': 31.317455619573593}\n",
            "Losses {'ner': 47.39156076312065}\n",
            "Losses {'ner': 67.76133915781975}\n",
            "Losses {'ner': 81.52789017558098}\n",
            "Losses {'ner': 102.19981476664543}\n",
            "Losses {'ner': 117.99584838747978}\n",
            "Losses {'ner': 131.27229069173336}\n",
            "Losses {'ner': 134.29208313068375}\n",
            "Losses {'ner': 18.14270853996277}\n",
            "Losses {'ner': 28.786418557167053}\n",
            "Losses {'ner': 40.27522051334381}\n",
            "Losses {'ner': 58.916160464286804}\n",
            "Losses {'ner': 72.96930468082428}\n",
            "Losses {'ner': 90.0298820734024}\n",
            "Losses {'ner': 110.48765361309052}\n",
            "Losses {'ner': 126.06891429424286}\n",
            "Losses {'ner': 132.6180420704186}\n",
            "Losses {'ner': 13.80591893196106}\n",
            "Losses {'ner': 37.819578409194946}\n",
            "Losses {'ner': 49.32086896896362}\n",
            "Losses {'ner': 68.17537653446198}\n",
            "Losses {'ner': 77.6608966588974}\n",
            "Losses {'ner': 91.40549957752228}\n",
            "Losses {'ner': 104.49340072274208}\n",
            "Losses {'ner': 118.42003884911537}\n",
            "Losses {'ner': 124.49680862762034}\n",
            "Losses {'ner': 21.45096480846405}\n",
            "Losses {'ner': 35.94009292125702}\n",
            "Losses {'ner': 55.570247769355774}\n",
            "Losses {'ner': 72.33398085832596}\n",
            "Losses {'ner': 90.05879908800125}\n",
            "Losses {'ner': 105.71178549528122}\n",
            "Losses {'ner': 117.23720675706863}\n",
            "Losses {'ner': 132.911627471447}\n",
            "Losses {'ner': 133.73390318453312}\n",
            "Losses {'ner': 13.78316354751587}\n",
            "Losses {'ner': 29.98029887676239}\n",
            "Losses {'ner': 49.137402176856995}\n",
            "Losses {'ner': 65.8111480474472}\n",
            "Losses {'ner': 79.95626986026764}\n",
            "Losses {'ner': 96.70929753780365}\n",
            "Losses {'ner': 109.55406737700105}\n",
            "Losses {'ner': 129.21068168058991}\n",
            "Losses {'ner': 130.54105019196868}\n",
            "Losses {'ner': 16.530163288116455}\n",
            "Losses {'ner': 35.106831789016724}\n",
            "Losses {'ner': 48.5562527179718}\n",
            "Losses {'ner': 69.43111503124237}\n",
            "Losses {'ner': 83.7365071773529}\n",
            "Losses {'ner': 107.45516657829285}\n",
            "Losses {'ner': 127.01212930679321}\n",
            "Losses {'ner': 142.62657940387726}\n",
            "Losses {'ner': 143.8782610911876}\n",
            "Losses {'ner': 16.96493363380432}\n",
            "Losses {'ner': 32.084089517593384}\n",
            "Losses {'ner': 48.17377519607544}\n",
            "Losses {'ner': 60.939828276634216}\n",
            "Losses {'ner': 81.61192762851715}\n",
            "Losses {'ner': 97.83327496051788}\n",
            "Losses {'ner': 115.52252471446991}\n",
            "Losses {'ner': 135.68561625480652}\n",
            "Losses {'ner': 140.1448690034449}\n",
            "Losses {'ner': 15.965368866920471}\n",
            "Losses {'ner': 33.327982664108276}\n",
            "Losses {'ner': 46.20104944705963}\n",
            "Losses {'ner': 71.31761181354523}\n",
            "Losses {'ner': 87.90618336200714}\n",
            "Losses {'ner': 102.3648693561554}\n",
            "Losses {'ner': 114.6926205046475}\n",
            "Losses {'ner': 122.37417729571462}\n",
            "Losses {'ner': 127.74621904268861}\n",
            "Losses {'ner': 17.357481956481934}\n",
            "Losses {'ner': 33.70405840873718}\n",
            "Losses {'ner': 49.599284648895264}\n",
            "Losses {'ner': 68.16609287261963}\n",
            "Losses {'ner': 86.59829473495483}\n",
            "Losses {'ner': 104.71957588195801}\n",
            "Losses {'ner': 123.234499335289}\n",
            "Losses {'ner': 139.53944736719131}\n",
            "Losses {'ner': 143.2048946171999}\n",
            "Losses {'ner': 19.553980112075806}\n",
            "Losses {'ner': 38.18597912788391}\n",
            "Losses {'ner': 54.71251463890076}\n",
            "Losses {'ner': 72.24915623664856}\n",
            "Losses {'ner': 86.30246269702911}\n",
            "Losses {'ner': 100.21079468727112}\n",
            "Losses {'ner': 111.98289120197296}\n",
            "Losses {'ner': 131.94227254390717}\n",
            "Losses {'ner': 135.29372483398765}\n",
            "Losses {'ner': 14.104132175445557}\n",
            "Losses {'ner': 30.854236602783203}\n",
            "Losses {'ner': 45.133383214473724}\n",
            "Losses {'ner': 63.70039612054825}\n",
            "Losses {'ner': 82.87027078866959}\n",
            "Losses {'ner': 98.3678589463234}\n",
            "Losses {'ner': 121.74742394685745}\n",
            "Losses {'ner': 134.80853861570358}\n",
            "Losses {'ner': 137.51294330507517}\n",
            "Losses {'ner': 13.893698573112488}\n",
            "Losses {'ner': 30.33222734928131}\n",
            "Losses {'ner': 43.186263024806976}\n",
            "Losses {'ner': 57.05879682302475}\n",
            "Losses {'ner': 71.83895879983902}\n",
            "Losses {'ner': 89.85206419229507}\n",
            "Losses {'ner': 106.06861001253128}\n",
            "Losses {'ner': 122.90013378858566}\n",
            "Losses {'ner': 123.51076515205204}\n",
            "Losses {'ner': 14.06092381477356}\n",
            "Losses {'ner': 26.579834043979645}\n",
            "Losses {'ner': 52.49963861703873}\n",
            "Losses {'ner': 57.85688737779856}\n",
            "Losses {'ner': 74.86362389475107}\n",
            "Losses {'ner': 94.73405078798532}\n",
            "Losses {'ner': 110.68028954416513}\n",
            "Losses {'ner': 119.87469803541899}\n",
            "Losses {'ner': 128.9816329330206}\n",
            "Losses {'ner': 13.706746578216553}\n",
            "Losses {'ner': 29.284706115722656}\n",
            "Losses {'ner': 48.60331869125366}\n",
            "Losses {'ner': 62.8801794052124}\n",
            "Losses {'ner': 72.93877583183348}\n",
            "Losses {'ner': 91.07484954036772}\n",
            "Losses {'ner': 110.79644673503935}\n",
            "Losses {'ner': 129.64522259868681}\n",
            "Losses {'ner': 133.434984754771}\n",
            "Losses {'ner': 18.334453463554382}\n",
            "Losses {'ner': 35.63287055492401}\n",
            "Losses {'ner': 48.78787326812744}\n",
            "Losses {'ner': 65.129607796669}\n",
            "Losses {'ner': 77.64047086238861}\n",
            "Losses {'ner': 89.98019468784332}\n",
            "Losses {'ner': 101.4556993842125}\n",
            "Losses {'ner': 114.04883826524019}\n",
            "Losses {'ner': 118.77683728188276}\n",
            "Losses {'ner': 11.986815214157104}\n",
            "Losses {'ner': 27.13039541244507}\n",
            "Losses {'ner': 41.091943860054016}\n",
            "Losses {'ner': 55.351407051086426}\n",
            "Losses {'ner': 71.4554374217987}\n",
            "Losses {'ner': 85.26447796821594}\n",
            "Losses {'ner': 104.26356077194214}\n",
            "Losses {'ner': 120.2235460281372}\n",
            "Losses {'ner': 125.08848361531335}\n",
            "Losses {'ner': 23.025816917419434}\n",
            "Losses {'ner': 41.653611183166504}\n",
            "Losses {'ner': 62.49569058418274}\n",
            "Losses {'ner': 77.73006463050842}\n",
            "Losses {'ner': 91.05715990066528}\n",
            "Losses {'ner': 103.22071170806885}\n",
            "Losses {'ner': 114.60629189014435}\n",
            "Losses {'ner': 128.01841163635254}\n",
            "Losses {'ner': 133.0715797767043}\n",
            "Losses {'ner': 10.622804164886475}\n",
            "Losses {'ner': 26.68317699432373}\n",
            "Losses {'ner': 34.59959256649017}\n",
            "Losses {'ner': 50.4654598236084}\n",
            "Losses {'ner': 67.69726538658142}\n",
            "Losses {'ner': 86.73187255859375}\n",
            "Losses {'ner': 97.27371153235435}\n",
            "Losses {'ner': 110.62166830897331}\n",
            "Losses {'ner': 112.80505277216434}\n",
            "Losses {'ner': 9.31029760837555}\n",
            "Losses {'ner': 28.494421005249023}\n",
            "Losses {'ner': 42.417898297309875}\n",
            "Losses {'ner': 53.6764617562294}\n",
            "Losses {'ner': 70.71749550104141}\n",
            "Losses {'ner': 88.9265587925911}\n",
            "Losses {'ner': 103.41402405500412}\n",
            "Losses {'ner': 118.35233110189438}\n",
            "Losses {'ner': 122.37476319819689}\n",
            "Losses {'ner': 15.001540660858154}\n",
            "Losses {'ner': 33.0433543920517}\n",
            "Losses {'ner': 49.05610716342926}\n",
            "Losses {'ner': 62.475664019584656}\n",
            "Losses {'ner': 77.77869194746017}\n",
            "Losses {'ner': 95.08517247438431}\n",
            "Losses {'ner': 116.6146474480629}\n",
            "Losses {'ner': 127.7621391415596}\n",
            "Losses {'ner': 133.8096712231636}\n",
            "Losses {'ner': 20.453867077827454}\n",
            "Losses {'ner': 32.49402666091919}\n",
            "Losses {'ner': 51.42903447151184}\n",
            "Losses {'ner': 66.63585066795349}\n",
            "Losses {'ner': 84.54761624336243}\n",
            "Losses {'ner': 99.90309572219849}\n",
            "Losses {'ner': 121.14430165290833}\n",
            "Losses {'ner': 135.81774878501892}\n",
            "Losses {'ner': 137.5046639556531}\n",
            "Losses {'ner': 16.978593468666077}\n",
            "Losses {'ner': 26.778241097927094}\n",
            "Losses {'ner': 45.362246572971344}\n",
            "Losses {'ner': 60.565851747989655}\n",
            "Losses {'ner': 76.8061848282814}\n",
            "Losses {'ner': 91.95485347509384}\n",
            "Losses {'ner': 109.30516237020493}\n",
            "Losses {'ner': 120.34620589017868}\n",
            "Losses {'ner': 123.99461668729782}\n",
            "Losses {'ner': 20.635895013809204}\n",
            "Losses {'ner': 44.2077739238739}\n",
            "Losses {'ner': 59.16586363315582}\n",
            "Losses {'ner': 73.60619294643402}\n",
            "Losses {'ner': 90.58740246295929}\n",
            "Losses {'ner': 110.63045680522919}\n",
            "Losses {'ner': 125.78471529483795}\n",
            "Losses {'ner': 142.9764582514763}\n",
            "Losses {'ner': 147.0266574015841}\n",
            "Losses {'ner': 14.717840909957886}\n",
            "Losses {'ner': 33.69142973423004}\n",
            "Losses {'ner': 45.79360508918762}\n",
            "Losses {'ner': 62.03179121017456}\n",
            "Losses {'ner': 78.09873652458191}\n",
            "Losses {'ner': 95.5720899105072}\n",
            "Losses {'ner': 115.8339536190033}\n",
            "Losses {'ner': 127.16429507732391}\n",
            "Losses {'ner': 130.56388018094003}\n",
            "Losses {'ner': 16.57923674583435}\n",
            "Losses {'ner': 28.489651203155518}\n",
            "Losses {'ner': 39.101519882678986}\n",
            "Losses {'ner': 49.406829953193665}\n",
            "Losses {'ner': 63.14075481891632}\n",
            "Losses {'ner': 83.32877922058105}\n",
            "Losses {'ner': 106.18980765342712}\n",
            "Losses {'ner': 120.8716561794281}\n",
            "Losses {'ner': 125.82318207621574}\n",
            "Losses {'ner': 12.064312815666199}\n",
            "Losses {'ner': 28.802743792533875}\n",
            "Losses {'ner': 46.22142446041107}\n",
            "Losses {'ner': 66.59290611743927}\n",
            "Losses {'ner': 82.99935948848724}\n",
            "Losses {'ner': 95.57486283779144}\n",
            "Losses {'ner': 107.77441465854645}\n",
            "Losses {'ner': 117.07830953598022}\n",
            "Losses {'ner': 120.33881885174196}\n",
            "Losses {'ner': 16.073193788528442}\n",
            "Losses {'ner': 34.87415409088135}\n",
            "Losses {'ner': 53.488271713256836}\n",
            "Losses {'ner': 67.9646327495575}\n",
            "Losses {'ner': 80.19689896702766}\n",
            "Losses {'ner': 95.76423671841621}\n",
            "Losses {'ner': 104.84298974275589}\n",
            "Losses {'ner': 115.44144865870476}\n",
            "Losses {'ner': 121.95713729783893}\n",
            "Losses {'ner': 13.716646194458008}\n",
            "Losses {'ner': 29.476608753204346}\n",
            "Losses {'ner': 44.570244669914246}\n",
            "Losses {'ner': 63.11603593826294}\n",
            "Losses {'ner': 81.10448789596558}\n",
            "Losses {'ner': 97.44027185440063}\n",
            "Losses {'ner': 109.74885129928589}\n",
            "Losses {'ner': 123.26950085163116}\n",
            "Losses {'ner': 127.35053722010343}\n",
            "Losses {'ner': 15.496397972106934}\n",
            "Losses {'ner': 28.230257272720337}\n",
            "Losses {'ner': 44.16931772232056}\n",
            "Losses {'ner': 62.71788287162781}\n",
            "Losses {'ner': 81.85785603523254}\n",
            "Losses {'ner': 98.27235531806946}\n",
            "Losses {'ner': 109.20530676841736}\n",
            "Losses {'ner': 125.90580940246582}\n",
            "Losses {'ner': 127.91375942819286}\n",
            "Losses {'ner': 15.795852184295654}\n",
            "Losses {'ner': 26.524991624057293}\n",
            "Losses {'ner': 39.29496394842863}\n",
            "Losses {'ner': 52.73333942145109}\n",
            "Losses {'ner': 76.04860793799162}\n",
            "Losses {'ner': 93.57682191580534}\n",
            "Losses {'ner': 105.45556878298521}\n",
            "Losses {'ner': 119.1938786432147}\n",
            "Losses {'ner': 123.24219904094934}\n",
            "Losses {'ner': 13.262203693389893}\n",
            "Losses {'ner': 26.274862051010132}\n",
            "Losses {'ner': 41.36876928806305}\n",
            "Losses {'ner': 58.95973742008209}\n",
            "Losses {'ner': 74.0423173904419}\n",
            "Losses {'ner': 88.11701261997223}\n",
            "Losses {'ner': 103.39606928825378}\n",
            "Losses {'ner': 121.18746018409729}\n",
            "Losses {'ner': 122.16712909866419}\n",
            "Losses {'ner': 12.063119649887085}\n",
            "Losses {'ner': 29.79332423210144}\n",
            "Losses {'ner': 43.186685025691986}\n",
            "Losses {'ner': 65.07780236005783}\n",
            "Losses {'ner': 81.65646129846573}\n",
            "Losses {'ner': 102.17588812112808}\n",
            "Losses {'ner': 120.08830219507217}\n",
            "Losses {'ner': 129.47507494688034}\n",
            "Losses {'ner': 136.64168560504913}\n",
            "Losses {'ner': 15.453295886516571}\n",
            "Losses {'ner': 32.73484057188034}\n",
            "Losses {'ner': 45.96108287572861}\n",
            "Losses {'ner': 60.918934762477875}\n",
            "Losses {'ner': 77.9215778708458}\n",
            "Losses {'ner': 93.71596497297287}\n",
            "Losses {'ner': 114.0586501955986}\n",
            "Losses {'ner': 134.57125061750412}\n",
            "Losses {'ner': 137.59490591287613}\n",
            "Losses {'ner': 16.80251121520996}\n",
            "Losses {'ner': 32.48794722557068}\n",
            "Losses {'ner': 50.437167286872864}\n",
            "Losses {'ner': 71.04685866832733}\n",
            "Losses {'ner': 88.75310981273651}\n",
            "Losses {'ner': 112.32597839832306}\n",
            "Losses {'ner': 126.79994028806686}\n",
            "Losses {'ner': 142.6930155158043}\n",
            "Losses {'ner': 148.02469298243523}\n",
            "Losses {'ner': 14.991587400436401}\n",
            "Losses {'ner': 32.86628341674805}\n",
            "Losses {'ner': 48.69377565383911}\n",
            "Losses {'ner': 62.03315085172653}\n",
            "Losses {'ner': 75.33040279150009}\n",
            "Losses {'ner': 91.25747436285019}\n",
            "Losses {'ner': 106.01252883672714}\n",
            "Losses {'ner': 119.19286721944809}\n",
            "Losses {'ner': 123.84923473605886}\n",
            "Losses {'ner': 18.8031804561615}\n",
            "Losses {'ner': 40.20600461959839}\n",
            "Losses {'ner': 53.86628723144531}\n",
            "Losses {'ner': 71.28989696502686}\n",
            "Losses {'ner': 83.69758641719818}\n",
            "Losses {'ner': 103.09824168682098}\n",
            "Losses {'ner': 117.49697959423065}\n",
            "Losses {'ner': 132.86390221118927}\n",
            "Losses {'ner': 137.15390622615814}\n",
            "Losses {'ner': 13.629980206489563}\n",
            "Losses {'ner': 28.456833481788635}\n",
            "Losses {'ner': 46.76413643360138}\n",
            "Losses {'ner': 65.20791471004486}\n",
            "Losses {'ner': 84.72368943691254}\n",
            "Losses {'ner': 100.62961900234222}\n",
            "Losses {'ner': 110.39007937908173}\n",
            "Losses {'ner': 125.9262844324112}\n",
            "Losses {'ner': 131.91141465306282}\n",
            "Losses {'ner': 11.712217211723328}\n",
            "Losses {'ner': 28.201855063438416}\n",
            "Losses {'ner': 39.80482316017151}\n",
            "Losses {'ner': 52.56957268714905}\n",
            "Losses {'ner': 65.47117042541504}\n",
            "Losses {'ner': 83.33328247070312}\n",
            "Losses {'ner': 111.34611129760742}\n",
            "Losses {'ner': 125.50499033927917}\n",
            "Losses {'ner': 128.22584203723818}\n",
            "Losses {'ner': 15.80808162689209}\n",
            "Losses {'ner': 32.785269021987915}\n",
            "Losses {'ner': 52.48602485656738}\n",
            "Losses {'ner': 64.86228227615356}\n",
            "Losses {'ner': 80.3627405166626}\n",
            "Losses {'ner': 97.58433187007904}\n",
            "Losses {'ner': 109.79588770866394}\n",
            "Losses {'ner': 126.41017436981201}\n",
            "Losses {'ner': 133.0055998750031}\n",
            "Losses {'ner': 19.816962003707886}\n",
            "Losses {'ner': 32.36931002140045}\n",
            "Losses {'ner': 55.38943088054657}\n",
            "Losses {'ner': 68.66454637050629}\n",
            "Losses {'ner': 82.15385055541992}\n",
            "Losses {'ner': 94.98062586784363}\n",
            "Losses {'ner': 109.55929708480835}\n",
            "Losses {'ner': 121.6784279346466}\n",
            "Losses {'ner': 127.45426544174552}\n",
            "Losses {'ner': 20.50359058380127}\n",
            "Losses {'ner': 34.11936104297638}\n",
            "Losses {'ner': 49.8412743806839}\n",
            "Losses {'ner': 64.87342154979706}\n",
            "Losses {'ner': 78.38284528255463}\n",
            "Losses {'ner': 99.85406374931335}\n",
            "Losses {'ner': 118.14718174934387}\n",
            "Losses {'ner': 127.95352559909225}\n",
            "Losses {'ner': 132.785584744066}\n",
            "Losses {'ner': 14.46177363395691}\n",
            "Losses {'ner': 30.41252064704895}\n",
            "Losses {'ner': 50.09912157058716}\n",
            "Losses {'ner': 64.61000978946686}\n",
            "Losses {'ner': 77.3657945394516}\n",
            "Losses {'ner': 90.23820352554321}\n",
            "Losses {'ner': 105.7298812866211}\n",
            "Losses {'ner': 125.81705260276794}\n",
            "Losses {'ner': 130.1550946449861}\n",
            "Losses {'ner': 15.762857049703598}\n",
            "Losses {'ner': 40.48426875472069}\n",
            "Losses {'ner': 57.92040714621544}\n",
            "Losses {'ner': 70.03504034876823}\n",
            "Losses {'ner': 82.27685424685478}\n",
            "Losses {'ner': 96.1043663918972}\n",
            "Losses {'ner': 107.11873105168343}\n",
            "Losses {'ner': 125.19175150990486}\n",
            "Losses {'ner': 127.47139866650105}\n",
            "Losses {'ner': 18.297807216644287}\n",
            "Losses {'ner': 34.025726556777954}\n",
            "Losses {'ner': 56.27025294303894}\n",
            "Losses {'ner': 69.73903894424438}\n",
            "Losses {'ner': 86.22104227542877}\n",
            "Losses {'ner': 102.88643085956573}\n",
            "Losses {'ner': 111.30431973934174}\n",
            "Losses {'ner': 126.0794290304184}\n",
            "Losses {'ner': 130.09978463500738}\n",
            "Losses {'ner': 13.208003997802734}\n",
            "Losses {'ner': 31.555528163909912}\n",
            "Losses {'ner': 52.772146701812744}\n",
            "Losses {'ner': 63.06721329689026}\n",
            "Losses {'ner': 74.95799469947815}\n",
            "Losses {'ner': 89.03109955787659}\n",
            "Losses {'ner': 102.25499367713928}\n",
            "Losses {'ner': 120.05844902992249}\n",
            "Losses {'ner': 120.37339397100732}\n",
            "Losses {'ner': 15.404538750648499}\n",
            "Losses {'ner': 25.266171038150787}\n",
            "Losses {'ner': 41.5878329873085}\n",
            "Losses {'ner': 52.339922703802586}\n",
            "Losses {'ner': 67.32098022848368}\n",
            "Losses {'ner': 86.3853007927537}\n",
            "Losses {'ner': 98.3974224999547}\n",
            "Losses {'ner': 109.6528369858861}\n",
            "Losses {'ner': 113.55254001170397}\n",
            "Losses {'ner': 15.58515977859497}\n",
            "Losses {'ner': 26.812711656093597}\n",
            "Losses {'ner': 45.97465652227402}\n",
            "Losses {'ner': 57.75826549530029}\n",
            "Losses {'ner': 69.1351683139801}\n",
            "Losses {'ner': 83.13040924072266}\n",
            "Losses {'ner': 101.1466748714447}\n",
            "Losses {'ner': 116.91138410568237}\n",
            "Losses {'ner': 124.77316761016846}\n",
            "Losses {'ner': 15.003289937973022}\n",
            "Losses {'ner': 35.90741991996765}\n",
            "Losses {'ner': 50.812358140945435}\n",
            "Losses {'ner': 65.92553555965424}\n",
            "Losses {'ner': 83.24315416812897}\n",
            "Losses {'ner': 100.08249008655548}\n",
            "Losses {'ner': 118.98783147335052}\n",
            "Losses {'ner': 136.76772677898407}\n",
            "Losses {'ner': 140.61178413033485}\n",
            "Losses {'ner': 12.19127869606018}\n",
            "Losses {'ner': 29.056615114212036}\n",
            "Losses {'ner': 45.247268319129944}\n",
            "Losses {'ner': 58.835516691207886}\n",
            "Losses {'ner': 73.50961911678314}\n",
            "Losses {'ner': 88.2602881193161}\n",
            "Losses {'ner': 98.97568786144257}\n",
            "Losses {'ner': 118.6834625005722}\n",
            "Losses {'ner': 120.5602832808454}\n",
            "Losses {'ner': 15.576860904693604}\n",
            "Losses {'ner': 30.708048582077026}\n",
            "Losses {'ner': 38.948620557785034}\n",
            "Losses {'ner': 59.07953977584839}\n",
            "Losses {'ner': 74.76002430915833}\n",
            "Losses {'ner': 83.75684440881014}\n",
            "Losses {'ner': 99.63191474229097}\n",
            "Losses {'ner': 113.72648382931948}\n",
            "Losses {'ner': 116.98273821920156}\n",
            "Losses {'ner': 17.549658060073853}\n",
            "Losses {'ner': 32.84443402290344}\n",
            "Losses {'ner': 48.742146253585815}\n",
            "Losses {'ner': 64.66850137710571}\n",
            "Losses {'ner': 83.93318963050842}\n",
            "Losses {'ner': 102.26173758506775}\n",
            "Losses {'ner': 112.02428621053696}\n",
            "Losses {'ner': 127.37536519765854}\n",
            "Losses {'ner': 131.46015137434006}\n",
            "Losses {'ner': 18.86313271522522}\n",
            "Losses {'ner': 32.710733294487}\n",
            "Losses {'ner': 48.131258845329285}\n",
            "Losses {'ner': 72.75494611263275}\n",
            "Losses {'ner': 88.15005922317505}\n",
            "Losses {'ner': 100.35224604606628}\n",
            "Losses {'ner': 112.11142897605896}\n",
            "Losses {'ner': 126.3503143787384}\n",
            "Losses {'ner': 130.71016270294785}\n",
            "Losses {'ner': 18.058339834213257}\n",
            "Losses {'ner': 39.657663106918335}\n",
            "Losses {'ner': 51.357675075531006}\n",
            "Losses {'ner': 67.30586791038513}\n",
            "Losses {'ner': 82.33798480033875}\n",
            "Losses {'ner': 96.25923705101013}\n",
            "Losses {'ner': 111.67332148551941}\n",
            "Losses {'ner': 131.34450125694275}\n",
            "Losses {'ner': 134.47427301766584}\n",
            "Losses {'ner': 9.651613593101501}\n",
            "Losses {'ner': 26.294419288635254}\n",
            "Losses {'ner': 34.70422029495239}\n",
            "Losses {'ner': 49.341309547424316}\n",
            "Losses {'ner': 70.96126222610474}\n",
            "Losses {'ner': 90.32051730155945}\n",
            "Losses {'ner': 108.41087460517883}\n",
            "Losses {'ner': 130.06883907318115}\n",
            "Losses {'ner': 132.17790111899376}\n",
            "Losses {'ner': 12.654345750808716}\n",
            "Losses {'ner': 29.811808824539185}\n",
            "Losses {'ner': 48.005544662475586}\n",
            "Losses {'ner': 59.300039887428284}\n",
            "Losses {'ner': 77.23625910282135}\n",
            "Losses {'ner': 92.60806000232697}\n",
            "Losses {'ner': 107.96976435184479}\n",
            "Losses {'ner': 124.94614517688751}\n",
            "Losses {'ner': 131.65507702494506}\n",
            "Losses {'ner': 15.332849025726318}\n",
            "Losses {'ner': 28.552101969718933}\n",
            "Losses {'ner': 43.51831328868866}\n",
            "Losses {'ner': 61.854339718818665}\n",
            "Losses {'ner': 75.71289718151093}\n",
            "Losses {'ner': 89.91350638866425}\n",
            "Losses {'ner': 105.37656605243683}\n",
            "Losses {'ner': 119.71292924880981}\n",
            "Losses {'ner': 124.50898054242134}\n",
            "Losses {'ner': 15.701722621917725}\n",
            "Losses {'ner': 36.88248944282532}\n",
            "Losses {'ner': 52.101330518722534}\n",
            "Losses {'ner': 66.49117267131805}\n",
            "Losses {'ner': 87.56299197673798}\n",
            "Losses {'ner': 100.93013286590576}\n",
            "Losses {'ner': 117.75591206550598}\n",
            "Losses {'ner': 140.95276999473572}\n",
            "Losses {'ner': 142.67699750581414}\n",
            "Losses {'ner': 13.863828420639038}\n",
            "Losses {'ner': 25.163678407669067}\n",
            "Losses {'ner': 42.34870982170105}\n",
            "Losses {'ner': 55.91327118873596}\n",
            "Losses {'ner': 69.80319964885712}\n",
            "Losses {'ner': 80.55058282613754}\n",
            "Losses {'ner': 93.6144112944603}\n",
            "Losses {'ner': 107.167859852314}\n",
            "Losses {'ner': 110.40768846116745}\n",
            "Losses {'ner': 16.114500999450684}\n",
            "Losses {'ner': 33.64467108249664}\n",
            "Losses {'ner': 50.66433656215668}\n",
            "Losses {'ner': 62.0005359351635}\n",
            "Losses {'ner': 80.07899448275566}\n",
            "Losses {'ner': 92.6745317876339}\n",
            "Losses {'ner': 103.67791363596916}\n",
            "Losses {'ner': 113.52925726771355}\n",
            "Losses {'ner': 117.61694924347103}\n",
            "Losses {'ner': 8.578235626220703}\n",
            "Losses {'ner': 21.914122819900513}\n",
            "Losses {'ner': 32.08490550518036}\n",
            "Losses {'ner': 49.77521193027496}\n",
            "Losses {'ner': 72.05693447589874}\n",
            "Losses {'ner': 87.88771605491638}\n",
            "Losses {'ner': 106.08635544776917}\n",
            "Losses {'ner': 120.63308119773865}\n",
            "Losses {'ner': 121.33395543985534}\n",
            "Losses {'ner': 12.363015532493591}\n",
            "Losses {'ner': 26.6120023727417}\n",
            "Losses {'ner': 44.11522936820984}\n",
            "Losses {'ner': 60.82013535499573}\n",
            "Losses {'ner': 75.45893800258636}\n",
            "Losses {'ner': 91.92712998390198}\n",
            "Losses {'ner': 103.96781837940216}\n",
            "Losses {'ner': 122.85283982753754}\n",
            "Losses {'ner': 126.90435099601746}\n",
            "Losses {'ner': 14.621482610702515}\n",
            "Losses {'ner': 28.695295333862305}\n",
            "Losses {'ner': 43.547450721263885}\n",
            "Losses {'ner': 60.934238374233246}\n",
            "Losses {'ner': 78.47415846586227}\n",
            "Losses {'ner': 94.26691168546677}\n",
            "Losses {'ner': 111.06400066614151}\n",
            "Losses {'ner': 126.4066761136055}\n",
            "Losses {'ner': 132.38537347316742}\n",
            "Losses {'ner': 18.030591011047363}\n",
            "Losses {'ner': 33.94404995441437}\n",
            "Losses {'ner': 51.339370369911194}\n",
            "Losses {'ner': 67.25863540172577}\n",
            "Losses {'ner': 82.25529682636261}\n",
            "Losses {'ner': 100.50081980228424}\n",
            "Losses {'ner': 116.84490072727203}\n",
            "Losses {'ner': 130.390680047567}\n",
            "Losses {'ner': 133.32521159946918}\n",
            "Losses {'ner': 12.402442693710327}\n",
            "Losses {'ner': 29.756882667541504}\n",
            "Losses {'ner': 42.53436553478241}\n",
            "Losses {'ner': 61.386070132255554}\n",
            "Losses {'ner': 81.37265622615814}\n",
            "Losses {'ner': 91.02340787649155}\n",
            "Losses {'ner': 110.35123246908188}\n",
            "Losses {'ner': 127.22414046525955}\n",
            "Losses {'ner': 128.42175491899252}\n",
            "Losses {'ner': 11.100159049034119}\n",
            "Losses {'ner': 23.138987481594086}\n",
            "Losses {'ner': 39.03107589483261}\n",
            "Losses {'ner': 52.02527993917465}\n",
            "Losses {'ner': 63.916565239429474}\n",
            "Losses {'ner': 81.87645190954208}\n",
            "Losses {'ner': 103.27348059415817}\n",
            "Losses {'ner': 118.26786470413208}\n",
            "Losses {'ner': 120.94021106488071}\n",
            "Losses {'ner': 12.040628135204315}\n",
            "Losses {'ner': 24.942493855953217}\n",
            "Losses {'ner': 43.91555279493332}\n",
            "Losses {'ner': 58.446522772312164}\n",
            "Losses {'ner': 66.62719470262527}\n",
            "Losses {'ner': 80.113021671772}\n",
            "Losses {'ner': 95.22675794363022}\n",
            "Losses {'ner': 108.8190090060234}\n",
            "Losses {'ner': 109.87458495795727}\n",
            "Losses {'ner': 17.853419303894043}\n",
            "Losses {'ner': 40.096373558044434}\n",
            "Losses {'ner': 54.52408695220947}\n",
            "Losses {'ner': 68.2069046497345}\n",
            "Losses {'ner': 81.021528840065}\n",
            "Losses {'ner': 88.79709208011627}\n",
            "Losses {'ner': 105.08690416812897}\n",
            "Losses {'ner': 116.6592726111412}\n",
            "Losses {'ner': 119.93868528306484}\n",
            "Losses {'ner': 14.826856791973114}\n",
            "Losses {'ner': 28.756355941295624}\n",
            "Losses {'ner': 41.36851209402084}\n",
            "Losses {'ner': 53.14691001176834}\n",
            "Losses {'ner': 64.35687500238419}\n",
            "Losses {'ner': 78.80600768327713}\n",
            "Losses {'ner': 94.94866341352463}\n",
            "Losses {'ner': 106.33012890815735}\n",
            "Losses {'ner': 110.41819197684526}\n",
            "Losses {'ner': 13.96176290512085}\n",
            "Losses {'ner': 28.133511543273926}\n",
            "Losses {'ner': 44.81082534790039}\n",
            "Losses {'ner': 63.956653356552124}\n",
            "Losses {'ner': 82.62361288070679}\n",
            "Losses {'ner': 98.35662484169006}\n",
            "Losses {'ner': 118.23959755897522}\n",
            "Losses {'ner': 136.1415457725525}\n",
            "Losses {'ner': 140.39270615577698}\n",
            "Losses {'ner': 23.646031856536865}\n",
            "Losses {'ner': 35.78052222728729}\n",
            "Losses {'ner': 47.140932977199554}\n",
            "Losses {'ner': 65.09109181165695}\n",
            "Losses {'ner': 85.26926225423813}\n",
            "Losses {'ner': 96.9497691988945}\n",
            "Losses {'ner': 113.33412784337997}\n",
            "Losses {'ner': 129.71844214200974}\n",
            "Losses {'ner': 133.9744304359192}\n",
            "Losses {'ner': 12.336282312870026}\n",
            "Losses {'ner': 28.332545697689056}\n",
            "Losses {'ner': 42.10611283779144}\n",
            "Losses {'ner': 54.32371932268143}\n",
            "Losses {'ner': 74.3929300904274}\n",
            "Losses {'ner': 94.5056625008583}\n",
            "Losses {'ner': 106.27481371164322}\n",
            "Losses {'ner': 119.59053200483322}\n",
            "Losses {'ner': 119.98301334679127}\n",
            "Losses {'ner': 10.269680619239807}\n",
            "Losses {'ner': 23.955164074897766}\n",
            "Losses {'ner': 45.13689172267914}\n",
            "Losses {'ner': 61.32400286197662}\n",
            "Losses {'ner': 84.46357262134552}\n",
            "Losses {'ner': 94.9323360323906}\n",
            "Losses {'ner': 112.04246538877487}\n",
            "Losses {'ner': 122.8646228313446}\n",
            "Losses {'ner': 126.72849184647202}\n",
            "Losses {'ner': 16.983933687210083}\n",
            "Losses {'ner': 33.61904013156891}\n",
            "Losses {'ner': 51.08082330226898}\n",
            "Losses {'ner': 68.43684136867523}\n",
            "Losses {'ner': 85.1656802892685}\n",
            "Losses {'ner': 99.61043429374695}\n",
            "Losses {'ner': 110.94238817691803}\n",
            "Losses {'ner': 129.13881886005402}\n",
            "Losses {'ner': 135.03707925975323}\n",
            "Losses {'ner': 14.536232233047485}\n",
            "Losses {'ner': 24.266344666481018}\n",
            "Losses {'ner': 41.18044650554657}\n",
            "Losses {'ner': 53.72572326660156}\n",
            "Losses {'ner': 71.52018451690674}\n",
            "Losses {'ner': 90.16229152679443}\n",
            "Losses {'ner': 107.99396753311157}\n",
            "Losses {'ner': 126.1922960281372}\n",
            "Losses {'ner': 128.43468786776066}\n",
            "Losses {'ner': 16.04650855064392}\n",
            "Losses {'ner': 32.7335901260376}\n",
            "Losses {'ner': 50.38782811164856}\n",
            "Losses {'ner': 64.23143744468689}\n",
            "Losses {'ner': 78.86840236186981}\n",
            "Losses {'ner': 97.99149262905121}\n",
            "Losses {'ner': 114.52751910686493}\n",
            "Losses {'ner': 128.12917411327362}\n",
            "Losses {'ner': 131.47549245727117}\n",
            "Losses {'ner': 17.279645204544067}\n",
            "Losses {'ner': 31.150855660438538}\n",
            "Losses {'ner': 47.34390211105347}\n",
            "Losses {'ner': 59.12663924694061}\n",
            "Losses {'ner': 71.33772629126906}\n",
            "Losses {'ner': 86.00368159636855}\n",
            "Losses {'ner': 101.32494657859206}\n",
            "Losses {'ner': 118.11345260962844}\n",
            "Losses {'ner': 121.36051070038229}\n",
            "Losses {'ner': 14.420019626617432}\n",
            "Losses {'ner': 32.17851662635803}\n",
            "Losses {'ner': 48.096503257751465}\n",
            "Losses {'ner': 60.64621019363403}\n",
            "Losses {'ner': 76.26288950443268}\n",
            "Losses {'ner': 89.96072828769684}\n",
            "Losses {'ner': 110.0976392030716}\n",
            "Losses {'ner': 133.43309557437897}\n",
            "Losses {'ner': 136.5400311946869}\n",
            "Losses {'ner': 18.604647397994995}\n",
            "Losses {'ner': 30.88160479068756}\n",
            "Losses {'ner': 47.9344516992569}\n",
            "Losses {'ner': 65.95729792118073}\n",
            "Losses {'ner': 77.93947124481201}\n",
            "Losses {'ner': 92.21403235197067}\n",
            "Losses {'ner': 105.55735951662064}\n",
            "Losses {'ner': 120.24545687437057}\n",
            "Losses {'ner': 124.44326806813478}\n",
            "Losses {'ner': 16.793480157852173}\n",
            "Losses {'ner': 28.64078974723816}\n",
            "Losses {'ner': 43.305612564086914}\n",
            "Losses {'ner': 56.88123106956482}\n",
            "Losses {'ner': 67.5165588259697}\n",
            "Losses {'ner': 90.28501003980637}\n",
            "Losses {'ner': 109.35774654150009}\n",
            "Losses {'ner': 124.8848130106926}\n",
            "Losses {'ner': 131.8404176235199}\n",
            "Losses {'ner': 17.728990077972412}\n",
            "Losses {'ner': 31.695005178451538}\n",
            "Losses {'ner': 49.15267729759216}\n",
            "Losses {'ner': 63.960407972335815}\n",
            "Losses {'ner': 77.85090446472168}\n",
            "Losses {'ner': 92.56299567222595}\n",
            "Losses {'ner': 106.27505648136139}\n",
            "Losses {'ner': 126.69956529140472}\n",
            "Losses {'ner': 134.37370910006575}\n",
            "Losses {'ner': 16.356573343276978}\n",
            "Losses {'ner': 30.378267288208008}\n",
            "Losses {'ner': 41.50778216123581}\n",
            "Losses {'ner': 62.53318804502487}\n",
            "Losses {'ner': 77.64728039503098}\n",
            "Losses {'ner': 93.09863251447678}\n",
            "Losses {'ner': 106.61152309179306}\n",
            "Losses {'ner': 120.23277467489243}\n",
            "Losses {'ner': 123.6840114019069}\n",
            "Losses {'ner': 11.771258533000946}\n",
            "Losses {'ner': 22.07063215970993}\n",
            "Losses {'ner': 40.00013905763626}\n",
            "Losses {'ner': 58.66436618566513}\n",
            "Losses {'ner': 74.94770151376724}\n",
            "Losses {'ner': 90.79508954286575}\n",
            "Losses {'ner': 101.37007409334183}\n",
            "Losses {'ner': 118.15333372354507}\n",
            "Losses {'ner': 124.18880045413971}\n",
            "Losses {'ner': 17.541940212249756}\n",
            "Losses {'ner': 30.331539750099182}\n",
            "Losses {'ner': 43.79934334754944}\n",
            "Losses {'ner': 53.95275956392288}\n",
            "Losses {'ner': 61.839405715465546}\n",
            "Losses {'ner': 73.76349663734436}\n",
            "Losses {'ner': 84.02568805217743}\n",
            "Losses {'ner': 98.13557505607605}\n",
            "Losses {'ner': 101.29191299486794}\n",
            "Losses {'ner': 14.39193868637085}\n",
            "Losses {'ner': 25.800945520401}\n",
            "Losses {'ner': 38.599584460258484}\n",
            "Losses {'ner': 51.98976528644562}\n",
            "Losses {'ner': 67.12763673067093}\n",
            "Losses {'ner': 87.15772014856339}\n",
            "Losses {'ner': 99.87848776578903}\n",
            "Losses {'ner': 118.20125263929367}\n",
            "Losses {'ner': 121.63347026238685}\n",
            "Losses {'ner': 12.017371594905853}\n",
            "Losses {'ner': 21.146914839744568}\n",
            "Losses {'ner': 33.30199837684631}\n",
            "Losses {'ner': 50.007920265197754}\n",
            "Losses {'ner': 60.70218527317047}\n",
            "Losses {'ner': 76.70041239261627}\n",
            "Losses {'ner': 91.37867391109467}\n",
            "Losses {'ner': 103.14132630825043}\n",
            "Losses {'ner': 109.38036701083183}\n",
            "Losses {'ner': 11.41617089509964}\n",
            "Losses {'ner': 30.969878494739532}\n",
            "Losses {'ner': 44.89648872613907}\n",
            "Losses {'ner': 63.63303405046463}\n",
            "Losses {'ner': 81.14975172281265}\n",
            "Losses {'ner': 93.7512474656105}\n",
            "Losses {'ner': 106.01224666833878}\n",
            "Losses {'ner': 121.47561198472977}\n",
            "Losses {'ner': 123.68135097707705}\n",
            "Losses {'ner': 18.802538871765137}\n",
            "Losses {'ner': 26.588856786489487}\n",
            "Losses {'ner': 44.65246710181236}\n",
            "Losses {'ner': 54.95037481188774}\n",
            "Losses {'ner': 66.88272294402122}\n",
            "Losses {'ner': 79.64089938998222}\n",
            "Losses {'ner': 91.8265463411808}\n",
            "Losses {'ner': 114.70267429947853}\n",
            "Losses {'ner': 118.19975483417511}\n",
            "Losses {'ner': 17.85961389541626}\n",
            "Losses {'ner': 33.839717507362366}\n",
            "Losses {'ner': 48.026137709617615}\n",
            "Losses {'ner': 64.06353521347046}\n",
            "Losses {'ner': 83.01846480369568}\n",
            "Losses {'ner': 92.88868713378906}\n",
            "Losses {'ner': 102.8622527718544}\n",
            "Losses {'ner': 117.44255238771439}\n",
            "Losses {'ner': 120.88256219636241}\n",
            "Losses {'ner': 17.217594504356384}\n",
            "Losses {'ner': 33.31506395339966}\n",
            "Losses {'ner': 46.25360321998596}\n",
            "Losses {'ner': 60.60648810863495}\n",
            "Losses {'ner': 80.91692674160004}\n",
            "Losses {'ner': 95.36820924282074}\n",
            "Losses {'ner': 104.91435211896896}\n",
            "Losses {'ner': 120.51651901006699}\n",
            "Losses {'ner': 125.34511131048203}\n",
            "Losses {'ner': 17.66737675666809}\n",
            "Losses {'ner': 32.179240584373474}\n",
            "Losses {'ner': 49.51070535182953}\n",
            "Losses {'ner': 66.65051329135895}\n",
            "Losses {'ner': 81.15935093164444}\n",
            "Losses {'ner': 95.62942487001419}\n",
            "Losses {'ner': 109.2602511048317}\n",
            "Losses {'ner': 128.63159281015396}\n",
            "Losses {'ner': 133.82896518707275}\n",
            "Losses {'ner': 14.260086297988892}\n",
            "Losses {'ner': 26.75970435142517}\n",
            "Losses {'ner': 41.99378299713135}\n",
            "Losses {'ner': 51.52311044931412}\n",
            "Losses {'ner': 70.98729974031448}\n",
            "Losses {'ner': 85.15278643369675}\n",
            "Losses {'ner': 100.10132211446762}\n",
            "Losses {'ner': 116.3526536822319}\n",
            "Losses {'ner': 120.83289708054508}\n",
            "Losses {'ner': 15.135190486907959}\n",
            "Losses {'ner': 24.09611974656582}\n",
            "Losses {'ner': 44.15584073960781}\n",
            "Losses {'ner': 58.96324311196804}\n",
            "Losses {'ner': 72.58382259309292}\n",
            "Losses {'ner': 88.09900771081448}\n",
            "Losses {'ner': 103.28856764733791}\n",
            "Losses {'ner': 118.01972948014736}\n",
            "Losses {'ner': 121.35360418260098}\n",
            "Losses {'ner': 17.41346549987793}\n",
            "Losses {'ner': 34.64516294002533}\n",
            "Losses {'ner': 52.29665458202362}\n",
            "Losses {'ner': 68.65923249721527}\n",
            "Losses {'ner': 81.12252902984619}\n",
            "Losses {'ner': 96.73701858520508}\n",
            "Losses {'ner': 103.37701933085918}\n",
            "Losses {'ner': 115.26944248378277}\n",
            "Losses {'ner': 121.64546023531832}\n",
            "Losses {'ner': 15.250574707984924}\n",
            "Losses {'ner': 29.010885775089264}\n",
            "Losses {'ner': 43.07965260744095}\n",
            "Losses {'ner': 58.04770714044571}\n",
            "Losses {'ner': 73.31092244386673}\n",
            "Losses {'ner': 84.27427572011948}\n",
            "Losses {'ner': 96.88174945116043}\n",
            "Losses {'ner': 108.40080586075783}\n",
            "Losses {'ner': 112.72448435390834}\n",
            "Losses {'ner': 12.55863642692566}\n",
            "Losses {'ner': 34.635156869888306}\n",
            "Losses {'ner': 51.93088936805725}\n",
            "Losses {'ner': 70.52168822288513}\n",
            "Losses {'ner': 84.9797431230545}\n",
            "Losses {'ner': 101.087273478508}\n",
            "Losses {'ner': 115.37278771400452}\n",
            "Losses {'ner': 121.28605836629868}\n",
            "Losses {'ner': 122.67919545900077}\n",
            "Losses {'ner': 16.353983879089355}\n",
            "Losses {'ner': 30.482157588005066}\n",
            "Losses {'ner': 46.97570812702179}\n",
            "Losses {'ner': 60.65519392490387}\n",
            "Losses {'ner': 72.70572769641876}\n",
            "Losses {'ner': 83.64356184005737}\n",
            "Losses {'ner': 99.26479578018188}\n",
            "Losses {'ner': 114.40269160270691}\n",
            "Losses {'ner': 121.60754138231277}\n",
            "Losses {'ner': 18.839557647705078}\n",
            "Losses {'ner': 29.3723064661026}\n",
            "Losses {'ner': 44.61745202541351}\n",
            "Losses {'ner': 58.48564946651459}\n",
            "Losses {'ner': 75.0406242609024}\n",
            "Losses {'ner': 88.64667904376984}\n",
            "Losses {'ner': 99.78720211982727}\n",
            "Losses {'ner': 111.22586166858673}\n",
            "Losses {'ner': 116.10507661104202}\n",
            "Losses {'ner': 13.093020915985107}\n",
            "Losses {'ner': 32.31035113334656}\n",
            "Losses {'ner': 46.901405453681946}\n",
            "Losses {'ner': 63.36057209968567}\n",
            "Losses {'ner': 83.87780690193176}\n",
            "Losses {'ner': 96.60800278186798}\n",
            "Losses {'ner': 111.5457534790039}\n",
            "Losses {'ner': 126.0878809094429}\n",
            "Losses {'ner': 131.002856656909}\n",
            "Losses {'ner': 13.068277895450592}\n",
            "Losses {'ner': 26.223334968090057}\n",
            "Losses {'ner': 36.65920475125313}\n",
            "Losses {'ner': 52.26731136441231}\n",
            "Losses {'ner': 70.95740976929665}\n",
            "Losses {'ner': 86.19439950585365}\n",
            "Losses {'ner': 103.36784854531288}\n",
            "Losses {'ner': 121.48798123002052}\n",
            "Losses {'ner': 125.40019377332646}\n",
            "Losses {'ner': 13.579977750778198}\n",
            "Losses {'ner': 27.671687364578247}\n",
            "Losses {'ner': 44.36310875415802}\n",
            "Losses {'ner': 63.15670049190521}\n",
            "Losses {'ner': 76.08443236351013}\n",
            "Losses {'ner': 94.52973318099976}\n",
            "Losses {'ner': 107.37827682495117}\n",
            "Losses {'ner': 123.05433535575867}\n",
            "Losses {'ner': 125.78644943237305}\n",
            "Losses {'ner': 15.880313634872437}\n",
            "Losses {'ner': 31.57301163673401}\n",
            "Losses {'ner': 45.40394163131714}\n",
            "Losses {'ner': 56.41764545440674}\n",
            "Losses {'ner': 69.58200085163116}\n",
            "Losses {'ner': 85.60248982906342}\n",
            "Losses {'ner': 103.23452031612396}\n",
            "Losses {'ner': 117.2928797006607}\n",
            "Losses {'ner': 121.08235500493174}\n",
            "Losses {'ner': 14.58805513381958}\n",
            "Losses {'ner': 30.801444172859192}\n",
            "Losses {'ner': 48.26963913440704}\n",
            "Losses {'ner': 59.07225036621094}\n",
            "Losses {'ner': 70.21726313233376}\n",
            "Losses {'ner': 87.22357895970345}\n",
            "Losses {'ner': 103.16733458638191}\n",
            "Losses {'ner': 115.93514302372932}\n",
            "Losses {'ner': 117.99183501205698}\n",
            "Losses {'ner': 13.264566898345947}\n",
            "Losses {'ner': 31.24160122871399}\n",
            "Losses {'ner': 45.044684410095215}\n",
            "Losses {'ner': 59.88150477409363}\n",
            "Losses {'ner': 71.61691653728485}\n",
            "Losses {'ner': 87.25518465042114}\n",
            "Losses {'ner': 101.97247612476349}\n",
            "Losses {'ner': 111.08929258584976}\n",
            "Losses {'ner': 112.10288478562143}\n",
            "Losses {'ner': 14.286423921585083}\n",
            "Losses {'ner': 31.315824270248413}\n",
            "Losses {'ner': 40.6016389131546}\n",
            "Losses {'ner': 54.45729887485504}\n",
            "Losses {'ner': 69.47725856304169}\n",
            "Losses {'ner': 82.79297536611557}\n",
            "Losses {'ner': 99.88473790884018}\n",
            "Losses {'ner': 111.80941718816757}\n",
            "Losses {'ner': 114.64769288338721}\n",
            "Losses {'ner': 11.671027064323425}\n",
            "Losses {'ner': 20.734634157270193}\n",
            "Losses {'ner': 36.058497067540884}\n",
            "Losses {'ner': 55.29366409406066}\n",
            "Losses {'ner': 71.42216050252318}\n",
            "Losses {'ner': 86.52471780404449}\n",
            "Losses {'ner': 100.76838409528136}\n",
            "Losses {'ner': 120.44900381192565}\n",
            "Losses {'ner': 124.21143782697618}\n",
            "Losses {'ner': 14.555752754211426}\n",
            "Losses {'ner': 33.285937666893005}\n",
            "Losses {'ner': 43.70164203643799}\n",
            "Losses {'ner': 52.7212375998497}\n",
            "Losses {'ner': 67.84842818975449}\n",
            "Losses {'ner': 79.041723549366}\n",
            "Losses {'ner': 91.75003189407289}\n",
            "Losses {'ner': 107.18063396774232}\n",
            "Losses {'ner': 110.1235703304701}\n",
            "Losses {'ner': 16.12957137823105}\n",
            "Losses {'ner': 29.644035637378693}\n",
            "Losses {'ner': 36.894567399518564}\n",
            "Losses {'ner': 54.302842288510874}\n",
            "Losses {'ner': 66.36922243167646}\n",
            "Losses {'ner': 78.07187977363355}\n",
            "Losses {'ner': 101.2703861289192}\n",
            "Losses {'ner': 116.48431387473829}\n",
            "Losses {'ner': 118.79889911715873}\n",
            "Losses {'ner': 19.265666961669922}\n",
            "Losses {'ner': 31.464057207107544}\n",
            "Losses {'ner': 48.66523718833923}\n",
            "Losses {'ner': 65.12275576591492}\n",
            "Losses {'ner': 77.93069529533386}\n",
            "Losses {'ner': 92.2725203037262}\n",
            "Losses {'ner': 105.83431136608124}\n",
            "Losses {'ner': 124.16291129589081}\n",
            "Losses {'ner': 124.17195366598571}\n",
            "Losses {'ner': 17.265379428863525}\n",
            "Losses {'ner': 34.283666372299194}\n",
            "Losses {'ner': 48.40964937210083}\n",
            "Losses {'ner': 64.36662697792053}\n",
            "Losses {'ner': 77.57971953600645}\n",
            "Losses {'ner': 93.15381418913603}\n",
            "Losses {'ner': 107.60524141043425}\n",
            "Losses {'ner': 122.4612433835864}\n",
            "Losses {'ner': 127.09191440418363}\n",
            "Losses {'ner': 7.760161519050598}\n",
            "Losses {'ner': 21.117183923721313}\n",
            "Losses {'ner': 31.925072073936462}\n",
            "Losses {'ner': 49.387595772743225}\n",
            "Losses {'ner': 60.22943067550659}\n",
            "Losses {'ner': 72.4824628829956}\n",
            "Losses {'ner': 93.17132806777954}\n",
            "Losses {'ner': 115.63099098205566}\n",
            "Losses {'ner': 118.49401887669228}\n",
            "Losses {'ner': 9.05694729089737}\n",
            "Losses {'ner': 17.98503080010414}\n",
            "Losses {'ner': 37.96259108185768}\n",
            "Losses {'ner': 52.46185925602913}\n",
            "Losses {'ner': 69.06394603848457}\n",
            "Losses {'ner': 84.48449543118477}\n",
            "Losses {'ner': 101.8998866379261}\n",
            "Losses {'ner': 117.20097187161446}\n",
            "Losses {'ner': 122.29810351133347}\n",
            "Losses {'ner': 19.413928389549255}\n",
            "Losses {'ner': 34.767024636268616}\n",
            "Losses {'ner': 44.71984875202179}\n",
            "Losses {'ner': 60.007182121276855}\n",
            "Losses {'ner': 69.83498299121857}\n",
            "Losses {'ner': 79.38280010223389}\n",
            "Losses {'ner': 91.98464250564575}\n",
            "Losses {'ner': 106.4654769897461}\n",
            "Losses {'ner': 112.23510353686288}\n",
            "Losses {'ner': 8.485545836389065}\n",
            "Losses {'ner': 27.947228871285915}\n",
            "Losses {'ner': 41.57928653806448}\n",
            "Losses {'ner': 52.77814146131277}\n",
            "Losses {'ner': 68.91904469579458}\n",
            "Losses {'ner': 87.84278961271048}\n",
            "Losses {'ner': 108.17656990140676}\n",
            "Losses {'ner': 122.41608759015799}\n",
            "Losses {'ner': 122.6813597467044}\n",
            "Losses {'ner': 14.468617677688599}\n",
            "Losses {'ner': 27.496339082717896}\n",
            "Losses {'ner': 46.86535024642944}\n",
            "Losses {'ner': 58.89385277032852}\n",
            "Losses {'ner': 72.64161664247513}\n",
            "Losses {'ner': 87.49303632974625}\n",
            "Losses {'ner': 104.76787322759628}\n",
            "Losses {'ner': 119.7657715678215}\n",
            "Losses {'ner': 121.89200729131699}\n",
            "Losses {'ner': 15.039743423461914}\n",
            "Losses {'ner': 29.200952112674713}\n",
            "Losses {'ner': 47.41601711511612}\n",
            "Losses {'ner': 58.39071875810623}\n",
            "Losses {'ner': 72.03825634717941}\n",
            "Losses {'ner': 85.24341398477554}\n",
            "Losses {'ner': 103.07643467187881}\n",
            "Losses {'ner': 114.47896939516068}\n",
            "Losses {'ner': 118.1038854928338}\n",
            "Losses {'ner': 15.579412639141083}\n",
            "Losses {'ner': 22.98975294828415}\n",
            "Losses {'ner': 35.04067474603653}\n",
            "Losses {'ner': 47.897686302661896}\n",
            "Losses {'ner': 62.926935255527496}\n",
            "Losses {'ner': 78.54791885614395}\n",
            "Losses {'ner': 94.59730607271194}\n",
            "Losses {'ner': 108.8855362534523}\n",
            "Losses {'ner': 108.93905200799054}\n",
            "Losses {'ner': 11.138812899589539}\n",
            "Losses {'ner': 26.433605909347534}\n",
            "Losses {'ner': 40.15751242637634}\n",
            "Losses {'ner': 51.44252264499664}\n",
            "Losses {'ner': 65.06282436847687}\n",
            "Losses {'ner': 79.50602900981903}\n",
            "Losses {'ner': 93.89016258716583}\n",
            "Losses {'ner': 111.39311349391937}\n",
            "Losses {'ner': 117.40258938074112}\n",
            "Losses {'ner': 12.89081072807312}\n",
            "Losses {'ner': 25.677160143852234}\n",
            "Losses {'ner': 42.31588923931122}\n",
            "Losses {'ner': 56.15251958370209}\n",
            "Losses {'ner': 68.9235452413559}\n",
            "Losses {'ner': 85.18734586238861}\n",
            "Losses {'ner': 97.5153466463089}\n",
            "Losses {'ner': 112.12187260389328}\n",
            "Losses {'ner': 113.2703124792315}\n",
            "Losses {'ner': 11.005327701568604}\n",
            "Losses {'ner': 28.154610872268677}\n",
            "Losses {'ner': 34.04154585674405}\n",
            "Losses {'ner': 51.192723739892244}\n",
            "Losses {'ner': 70.66792391613126}\n",
            "Losses {'ner': 79.84375892952085}\n",
            "Losses {'ner': 95.32586370781064}\n",
            "Losses {'ner': 112.96604119613767}\n",
            "Losses {'ner': 118.89130012847454}\n",
            "Losses {'ner': 15.129830598831177}\n",
            "Losses {'ner': 30.943126678466797}\n",
            "Losses {'ner': 44.42296767234802}\n",
            "Losses {'ner': 58.64595913887024}\n",
            "Losses {'ner': 68.37204599380493}\n",
            "Losses {'ner': 82.35079228878021}\n",
            "Losses {'ner': 92.68709909915924}\n",
            "Losses {'ner': 107.92342960834503}\n",
            "Losses {'ner': 110.34161088243127}\n",
            "Losses {'ner': 8.806895941495895}\n",
            "Losses {'ner': 24.782095164060593}\n",
            "Losses {'ner': 30.157718624919653}\n",
            "Losses {'ner': 43.61079188808799}\n",
            "Losses {'ner': 56.33211978897452}\n",
            "Losses {'ner': 71.86596676334739}\n",
            "Losses {'ner': 86.65876790508628}\n",
            "Losses {'ner': 100.64565392956138}\n",
            "Losses {'ner': 106.47751146182418}\n",
            "Losses {'ner': 14.968469142913818}\n",
            "Losses {'ner': 32.135034799575806}\n",
            "Losses {'ner': 45.33935242891312}\n",
            "Losses {'ner': 57.29514962434769}\n",
            "Losses {'ner': 72.15362244844437}\n",
            "Losses {'ner': 86.10283094644547}\n",
            "Losses {'ner': 100.82050901651382}\n",
            "Losses {'ner': 111.59203237295151}\n",
            "Losses {'ner': 116.60089576244354}\n",
            "Losses {'ner': 14.900793075561523}\n",
            "Losses {'ner': 31.62352204322815}\n",
            "Losses {'ner': 45.13422191143036}\n",
            "Losses {'ner': 61.93248701095581}\n",
            "Losses {'ner': 75.05263876914978}\n",
            "Losses {'ner': 87.43162655830383}\n",
            "Losses {'ner': 102.8394193649292}\n",
            "Losses {'ner': 115.96331131458282}\n",
            "Losses {'ner': 118.72977291513234}\n",
            "Losses {'ner': 13.70805811882019}\n",
            "Losses {'ner': 28.060638189315796}\n",
            "Losses {'ner': 43.41484498977661}\n",
            "Losses {'ner': 63.48104548454285}\n",
            "Losses {'ner': 84.33970308303833}\n",
            "Losses {'ner': 97.48992729187012}\n",
            "Losses {'ner': 107.38445693254471}\n",
            "Losses {'ner': 124.42863494157791}\n",
            "Losses {'ner': 128.62718522548676}\n",
            "Losses {'ner': 20.399163961410522}\n",
            "Losses {'ner': 41.11670517921448}\n",
            "Losses {'ner': 50.89636665582657}\n",
            "Losses {'ner': 67.67759543657303}\n",
            "Losses {'ner': 78.25744980573654}\n",
            "Losses {'ner': 92.21821063756943}\n",
            "Losses {'ner': 107.19416779279709}\n",
            "Losses {'ner': 117.1187347099185}\n",
            "Losses {'ner': 119.25394326867536}\n",
            "Losses {'ner': 14.47642433643341}\n",
            "Losses {'ner': 27.36033856868744}\n",
            "Losses {'ner': 43.95690202713013}\n",
            "Losses {'ner': 58.455328702926636}\n",
            "Losses {'ner': 75.80494737625122}\n",
            "Losses {'ner': 91.84376263618469}\n",
            "Losses {'ner': 107.15251755714417}\n",
            "Losses {'ner': 119.79260563850403}\n",
            "Losses {'ner': 125.22118869423866}\n",
            "Losses {'ner': 16.78019618988037}\n",
            "Losses {'ner': 33.76345157623291}\n",
            "Losses {'ner': 47.39339196681976}\n",
            "Losses {'ner': 58.79176867008209}\n",
            "Losses {'ner': 73.08071732521057}\n",
            "Losses {'ner': 91.57386600971222}\n",
            "Losses {'ner': 107.30799973011017}\n",
            "Losses {'ner': 118.51143577694893}\n",
            "Losses {'ner': 119.57421026099473}\n",
            "Losses {'ner': 10.101698875427246}\n",
            "Losses {'ner': 26.545655488967896}\n",
            "Losses {'ner': 43.445061445236206}\n",
            "Losses {'ner': 56.907121658325195}\n",
            "Losses {'ner': 68.2501263320446}\n",
            "Losses {'ner': 80.21294781565666}\n",
            "Losses {'ner': 99.95223066210747}\n",
            "Losses {'ner': 113.33769336342812}\n",
            "Losses {'ner': 113.59818602539599}\n",
            "Losses {'ner': 13.89216434955597}\n",
            "Losses {'ner': 26.58460521697998}\n",
            "Losses {'ner': 39.93295741081238}\n",
            "Losses {'ner': 46.20937577076256}\n",
            "Losses {'ner': 58.566688772290945}\n",
            "Losses {'ner': 68.04530235379934}\n",
            "Losses {'ner': 86.22971888631582}\n",
            "Losses {'ner': 102.81678863614798}\n",
            "Losses {'ner': 106.86250115255825}\n",
            "Losses {'ner': 14.414834260940552}\n",
            "Losses {'ner': 24.987277269363403}\n",
            "Losses {'ner': 33.40844374895096}\n",
            "Losses {'ner': 44.954021751880646}\n",
            "Losses {'ner': 60.11871653795242}\n",
            "Losses {'ner': 74.2130919098854}\n",
            "Losses {'ner': 88.46844774484634}\n",
            "Losses {'ner': 104.25924450159073}\n",
            "Losses {'ner': 106.7835313294463}\n",
            "Losses {'ner': 9.522619904950261}\n",
            "Losses {'ner': 32.53106230683625}\n",
            "Losses {'ner': 44.44087201543152}\n",
            "Losses {'ner': 56.431550266221166}\n",
            "Losses {'ner': 68.20528304763138}\n",
            "Losses {'ner': 85.90143406577408}\n",
            "Losses {'ner': 96.55317902751267}\n",
            "Losses {'ner': 107.28063202090561}\n",
            "Losses {'ner': 108.98438885906944}\n",
            "Losses {'ner': 14.752639174461365}\n",
            "Losses {'ner': 30.61556839942932}\n",
            "Losses {'ner': 46.37464725971222}\n",
            "Losses {'ner': 59.83099031448364}\n",
            "Losses {'ner': 73.18143784999847}\n",
            "Losses {'ner': 90.60167682170868}\n",
            "Losses {'ner': 109.11509609222412}\n",
            "Losses {'ner': 126.52209854125977}\n",
            "Losses {'ner': 131.21074229478836}\n",
            "Losses {'ner': 13.842868089675903}\n",
            "Losses {'ner': 27.358377635478973}\n",
            "Losses {'ner': 42.63291996717453}\n",
            "Losses {'ner': 57.19328707456589}\n",
            "Losses {'ner': 74.53321105241776}\n",
            "Losses {'ner': 84.77016234397888}\n",
            "Losses {'ner': 99.92243981361389}\n",
            "Losses {'ner': 112.54424405097961}\n",
            "Losses {'ner': 117.36635625362396}\n",
            "Losses {'ner': 10.731389164924622}\n",
            "Losses {'ner': 23.50221198797226}\n",
            "Losses {'ner': 38.40928643941879}\n",
            "Losses {'ner': 52.19710785150528}\n",
            "Losses {'ner': 67.25655108690262}\n",
            "Losses {'ner': 83.71917396783829}\n",
            "Losses {'ner': 97.22916048765182}\n",
            "Losses {'ner': 109.22377747297287}\n",
            "Losses {'ner': 110.40229335194454}\n",
            "Losses {'ner': 10.900131464004517}\n",
            "Losses {'ner': 23.197564005851746}\n",
            "Losses {'ner': 41.50913453102112}\n",
            "Losses {'ner': 54.55857443809509}\n",
            "Losses {'ner': 69.5206367969513}\n",
            "Losses {'ner': 82.39684522151947}\n",
            "Losses {'ner': 95.81264102458954}\n",
            "Losses {'ner': 114.5259782075882}\n",
            "Losses {'ner': 118.08083337280777}\n",
            "Losses {'ner': 13.225935816764832}\n",
            "Losses {'ner': 31.033544659614563}\n",
            "Losses {'ner': 45.76869189739227}\n",
            "Losses {'ner': 55.21738398075104}\n",
            "Losses {'ner': 68.93768346309662}\n",
            "Losses {'ner': 85.43674910068512}\n",
            "Losses {'ner': 98.10099256038666}\n",
            "Losses {'ner': 109.2225193977356}\n",
            "Losses {'ner': 114.11057387944311}\n",
            "Losses {'ner': 19.42379093170166}\n",
            "Losses {'ner': 36.78851556777954}\n",
            "Losses {'ner': 49.82602059841156}\n",
            "Losses {'ner': 66.85640180110931}\n",
            "Losses {'ner': 79.70482933521271}\n",
            "Losses {'ner': 91.13060820102692}\n",
            "Losses {'ner': 106.07553446292877}\n",
            "Losses {'ner': 123.33320963382721}\n",
            "Losses {'ner': 126.47215130925179}\n",
            "Losses {'ner': 17.989548921585083}\n",
            "Losses {'ner': 32.128191232681274}\n",
            "Losses {'ner': 44.11023938655853}\n",
            "Losses {'ner': 59.57493197917938}\n",
            "Losses {'ner': 76.78202760219574}\n",
            "Losses {'ner': 91.10645842552185}\n",
            "Losses {'ner': 102.14532060548663}\n",
            "Losses {'ner': 111.86727751418948}\n",
            "Losses {'ner': 114.94478686705406}\n",
            "Losses {'ner': 19.29775309562683}\n",
            "Losses {'ner': 36.16242861747742}\n",
            "Losses {'ner': 51.61732268333435}\n",
            "Losses {'ner': 66.57396793365479}\n",
            "Losses {'ner': 78.38412892818451}\n",
            "Losses {'ner': 93.45079159736633}\n",
            "Losses {'ner': 109.10657668113708}\n",
            "Losses {'ner': 120.716224193573}\n",
            "Losses {'ner': 124.64848886232357}\n",
            "Losses {'ner': 15.209182739257812}\n",
            "Losses {'ner': 29.307131703943014}\n",
            "Losses {'ner': 46.38042562827468}\n",
            "Losses {'ner': 58.7756536565721}\n",
            "Losses {'ner': 69.10116111347452}\n",
            "Losses {'ner': 81.06459437916055}\n",
            "Losses {'ner': 95.5568486363627}\n",
            "Losses {'ner': 116.01583038875833}\n",
            "Losses {'ner': 120.79070994863287}\n",
            "Losses {'ner': 12.907979488372803}\n",
            "Losses {'ner': 26.2927268743515}\n",
            "Losses {'ner': 37.10523188114166}\n",
            "Losses {'ner': 49.270230412483215}\n",
            "Losses {'ner': 72.21853458881378}\n",
            "Losses {'ner': 87.31952202320099}\n",
            "Losses {'ner': 99.41391098499298}\n",
            "Losses {'ner': 111.35062086582184}\n",
            "Losses {'ner': 114.15976296726161}\n",
            "Losses {'ner': 8.233398169279099}\n",
            "Losses {'ner': 18.37720713019371}\n",
            "Losses {'ner': 32.275914400815964}\n",
            "Losses {'ner': 44.106498926877975}\n",
            "Losses {'ner': 60.51507517695427}\n",
            "Losses {'ner': 82.87352654337883}\n",
            "Losses {'ner': 97.13910457491875}\n",
            "Losses {'ner': 108.01675739884377}\n",
            "Losses {'ner': 115.32009486667812}\n",
            "Losses {'ner': 16.396360635757446}\n",
            "Losses {'ner': 32.22509956359863}\n",
            "Losses {'ner': 42.16257429122925}\n",
            "Losses {'ner': 57.47706735134125}\n",
            "Losses {'ner': 75.3828901052475}\n",
            "Losses {'ner': 83.53621380031109}\n",
            "Losses {'ner': 94.76825730502605}\n",
            "Losses {'ner': 107.83882610499859}\n",
            "Losses {'ner': 111.1042113378644}\n",
            "Losses {'ner': 12.993922472000122}\n",
            "Losses {'ner': 27.410603880882263}\n",
            "Losses {'ner': 44.10013151168823}\n",
            "Losses {'ner': 57.4366979598999}\n",
            "Losses {'ner': 70.1012978553772}\n",
            "Losses {'ner': 87.1062343120575}\n",
            "Losses {'ner': 100.92856931686401}\n",
            "Losses {'ner': 116.82647275924683}\n",
            "Losses {'ner': 120.89221646636724}\n",
            "Losses {'ner': 12.76246428489685}\n",
            "Losses {'ner': 27.449238300323486}\n",
            "Losses {'ner': 44.01488780975342}\n",
            "Losses {'ner': 57.912606954574585}\n",
            "Losses {'ner': 72.89069628715515}\n",
            "Losses {'ner': 84.78843486309052}\n",
            "Losses {'ner': 99.62417995929718}\n",
            "Losses {'ner': 112.80356347560883}\n",
            "Losses {'ner': 116.68457258306444}\n",
            "Losses {'ner': 12.621784448623657}\n",
            "Losses {'ner': 25.62282705307007}\n",
            "Losses {'ner': 43.724387645721436}\n",
            "Losses {'ner': 57.157402992248535}\n",
            "Losses {'ner': 72.32546579837799}\n",
            "Losses {'ner': 84.43448805809021}\n",
            "Losses {'ner': 95.4492335319519}\n",
            "Losses {'ner': 110.63790714740753}\n",
            "Losses {'ner': 115.77461943030357}\n",
            "Losses {'ner': 10.395195364952087}\n",
            "Losses {'ner': 22.36564600467682}\n",
            "Losses {'ner': 31.489414274692535}\n",
            "Losses {'ner': 39.619880363345146}\n",
            "Losses {'ner': 58.16346041858196}\n",
            "Losses {'ner': 77.45526759326458}\n",
            "Losses {'ner': 89.24275080859661}\n",
            "Losses {'ner': 105.94836799800396}\n",
            "Losses {'ner': 111.51584111899137}\n",
            "Losses {'ner': 11.480509281158447}\n",
            "Losses {'ner': 24.58281660079956}\n",
            "Losses {'ner': 43.45786213874817}\n",
            "Losses {'ner': 55.51666843891144}\n",
            "Losses {'ner': 72.40499699115753}\n",
            "Losses {'ner': 84.13473296165466}\n",
            "Losses {'ner': 96.04777210950851}\n",
            "Losses {'ner': 108.16665977239609}\n",
            "Losses {'ner': 113.16455841064453}\n",
            "Losses {'ner': 14.451772332191467}\n",
            "Losses {'ner': 26.140876919031143}\n",
            "Losses {'ner': 44.7649966776371}\n",
            "Losses {'ner': 60.476800590753555}\n",
            "Losses {'ner': 72.73475947976112}\n",
            "Losses {'ner': 85.45236018300056}\n",
            "Losses {'ner': 97.27047768235207}\n",
            "Losses {'ner': 116.2422665655613}\n",
            "Losses {'ner': 118.68851088349402}\n",
            "Losses {'ner': 13.22698974609375}\n",
            "Losses {'ner': 28.046176433563232}\n",
            "Losses {'ner': 41.312389612197876}\n",
            "Losses {'ner': 53.48370575904846}\n",
            "Losses {'ner': 66.8086724281311}\n",
            "Losses {'ner': 81.1387864947319}\n",
            "Losses {'ner': 93.80974072217941}\n",
            "Losses {'ner': 105.01036554574966}\n",
            "Losses {'ner': 109.52632565237582}\n",
            "Losses {'ner': 9.442447371780872}\n",
            "Losses {'ner': 21.79224706441164}\n",
            "Losses {'ner': 35.4540431573987}\n",
            "Losses {'ner': 45.20842135697603}\n",
            "Losses {'ner': 58.67514992505312}\n",
            "Losses {'ner': 70.54926205426455}\n",
            "Losses {'ner': 84.54805494099855}\n",
            "Losses {'ner': 99.57480431348085}\n",
            "Losses {'ner': 103.37750720572512}\n",
            "Losses {'ner': 9.079723358154297}\n",
            "Losses {'ner': 23.418205857276917}\n",
            "Losses {'ner': 38.09616696834564}\n",
            "Losses {'ner': 52.73222494125366}\n",
            "Losses {'ner': 74.1977059841156}\n",
            "Losses {'ner': 87.63086223602295}\n",
            "Losses {'ner': 100.3491860628128}\n",
            "Losses {'ner': 114.97053629159927}\n",
            "Losses {'ner': 119.81493785232306}\n",
            "Losses {'ner': 15.208255171775818}\n",
            "Losses {'ner': 28.325212836265564}\n",
            "Losses {'ner': 42.98584187030792}\n",
            "Losses {'ner': 52.03762078285217}\n",
            "Losses {'ner': 67.45918154716492}\n",
            "Losses {'ner': 80.64415514469147}\n",
            "Losses {'ner': 95.54087293148041}\n",
            "Losses {'ner': 110.61498248577118}\n",
            "Losses {'ner': 114.82131624221802}\n",
            "Losses {'ner': 13.808721542358398}\n",
            "Losses {'ner': 29.48365044593811}\n",
            "Losses {'ner': 44.13252532482147}\n",
            "Losses {'ner': 59.56018006801605}\n",
            "Losses {'ner': 73.85319030284882}\n",
            "Losses {'ner': 88.36646807193756}\n",
            "Losses {'ner': 99.64156377315521}\n",
            "Losses {'ner': 114.9012678861618}\n",
            "Losses {'ner': 119.08909182210846}\n",
            "Losses {'ner': 15.23443055152893}\n",
            "Losses {'ner': 27.386931896209717}\n",
            "Losses {'ner': 42.00808012485504}\n",
            "Losses {'ner': 57.492663741111755}\n",
            "Losses {'ner': 67.27738988399506}\n",
            "Losses {'ner': 70.36221871618181}\n",
            "Losses {'ner': 85.78935299161822}\n",
            "Losses {'ner': 98.31460664514452}\n",
            "Losses {'ner': 102.4506939733401}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgM-slynIOt9"
      },
      "source": [
        "Testing the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "grQ7IFUV48Rw",
        "outputId": "89f6d1ad-3efc-4774-d2a9-ed6f03b42375"
      },
      "source": [
        "doc_test = nlp_train(\"Fridge need to be replaced ASAP. Dorothy has a dog named Toto. Horses are tall.\")\n",
        "displacy.render(doc_test, \"ent\", jupyter=True)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Fridge\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
              "</mark>\n",
              " need to be replaced ASAP. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Dorothy\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " has a dog named \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Toto\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              ". \n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Horses\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ANIMAL</span>\n",
              "</mark>\n",
              " are tall.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rF4iPFMH_Le"
      },
      "source": [
        "test_without = [nlp(\"Horses have weak legs.\"),\n",
        "        nlp(\"Rabbits are nice.\"),\n",
        "        nlp(\"Shriya is nice.\"),\n",
        "        nlp(\"I bought a new car. Ansh already asked to drive it.\"),\n",
        "        nlp(\"Roland owns a watch.\") ,\n",
        "        nlp(\"Snakes are predators.\"),\n",
        "        nlp(\"I threw away my old laptop.\"),\n",
        "        nlp(\"I saw a snake today.\")]"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 461
        },
        "id": "1vF9uI8bIW3X",
        "outputId": "b09c16e7-5dbe-416e-a481-3e2c00ad1414"
      },
      "source": [
        "from spacy import displacy\n",
        "for item in test_without:\n",
        "  displacy.render(item, style=\"ent\", jupyter=True)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Horses have weak legs.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Rabbits are nice.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Shriya\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " is nice.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I bought a new car. \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Ansh\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " already asked to drive it.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Roland\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              " owns a watch.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">Snakes are predators.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I threw away my old laptop.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I saw a snake \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    today\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              ".</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jds17w0M6x_8"
      },
      "source": [
        "test = [nlp_train(\"Horses have weak legs.\"),\n",
        "        nlp_train(\"Rabbits are nice.\"),\n",
        "        nlp_train(\"Shriya is nice.\"),\n",
        "        nlp_train(\"I bought a new car. Ansh already asked to drive it.\"),\n",
        "        nlp_train(\"Roland owns a watch.\") ,\n",
        "        nlp_train(\"Snakes are predators.\"),\n",
        "        nlp_train(\"I threw away my old laptop.\"),\n",
        "        nlp_train(\"I saw a snake today.\")]"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "id": "zW1yYbvw7D6c",
        "outputId": "89914db1-0fbc-4a93-b9e8-ff9aaa94c625"
      },
      "source": [
        "from spacy import displacy\n",
        "for item in test:\n",
        "  displacy.render(item, style=\"ent\", jupyter=True)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Horses\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ANIMAL</span>\n",
              "</mark>\n",
              " have weak legs.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Rabbits\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ANIMALS</span>\n",
              "</mark>\n",
              " are nice.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Shriya\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " is nice.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I bought a new \n",
              "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    car\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
              "</mark>\n",
              ". \n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Ansh\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " already asked to drive it.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #aa9cfc; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Roland\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PERSON</span>\n",
              "</mark>\n",
              " owns a \n",
              "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    watch\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
              "</mark>\n",
              ".</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
              "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    Snakes\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ANIMALS</span>\n",
              "</mark>\n",
              " are predators.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I threw away my old \n",
              "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
              "    laptop\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
              "</mark>\n",
              ".</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/lib/python3.6/runpy.py:193: UserWarning: [W006] No entities to visualize found in Doc object. If this is surprising to you, make sure the Doc was processed using a model that supports named entity recognition, and check the `doc.ents` property manually if necessary.\n",
            "  \"__main__\", mod_spec)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">I saw a snake today.</div></span>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zwkv1PfpQDH8"
      },
      "source": [
        "As you can see, objects that weren't even mentioned in the training data have now been identified. We know that the model is not rote learning because snake got identified in one sentence but not in the other.\n",
        "\n",
        "**Bonuses:** \n",
        "\n",
        "1.   Run the test data on a new nlp object, what happens?\n",
        "2.   Try adding more data to the training data. Try running the training a couple times. Do you see any changes in the results?\n",
        "3.    Try to add a new pos to the model."
      ]
    }
  ]
}